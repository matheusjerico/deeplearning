{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução a DeepLearning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Função Softmax:\n",
    "Converter o score em probabilidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hot Enconding:\n",
    "Transformação de uma variável categórica em variável numérica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stochastic Gradient Descent:\n",
    "\n",
    "O treinamento de uma rede neural é convertido em um problema de otimização, com o objetivo de minimizar o erro cometido pela rede.\n",
    "\n",
    "Versão do Gradient Descent em que trabalha com amostras aleatórias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Momentum e Learning Rate\n",
    "\n",
    "Momentum: Incorpora as propriedades da atualização do peso anterior e faz com que os pesos continuem sendo atualizados na mesma direção mesmo que o erro diminui.\n",
    "\n",
    "Learning Rate Decay: Learning rate decay, é usado para diminuir o valor do learning rate conforme os erros diminuem.\n",
    "\n",
    "Learning Rate: 0,01 a 0,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regularização e Droupout\n",
    "\n",
    "Regularização: Método que busca melhorar a capacidade de generalização dos algoritmos de aprendizado por meio de alguma restrição durante a fase de trainamento (ajuda a generalizar o modelo e evitar overfitting).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando módulos\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando a reprodutividade do código\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega os dados\n",
    "dataset = numpy.loadtxt(\"/home/matheusjerico/Documentos/DSA/05. MachineLearning/Cap-12-IntroduçãoDeepLearning/Arquivos-Keras/pima-indians-diabetes.csv\", delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa as variáveis 'x' e 'y'\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.DataFrame(X)\n",
    "df_y = pd.DataFrame(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1     2     3    4     5      6     7\n",
       "0  6.0  148.0  72.0  35.0  0.0  33.6  0.627  50.0\n",
       "1  1.0   85.0  66.0  29.0  0.0  26.6  0.351  31.0\n",
       "2  8.0  183.0  64.0   0.0  0.0  23.3  0.672  32.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa os dados entre treino e teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_x, df_y, test_size = 0.3, random_state = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos em Keras são definidos como uma sequência de camadas. Isto facilita a criação do modelo, bastando inserir uma camada por vez até que estejamos satisfeitos com a topologia da rede.\n",
    "\n",
    "A primeira coisa a se fazer é garantir que a camada de entrada tem o número correto de inputs. Isto pode ser especificado enquanto criando a primeira camada com o argumento ‘input_dim’, atribuindo-lhe 8, para o variáveis de entrada. No exemplo a estrutura de rede é fully-connected com 3 camadas. Isto é, todos os neurônios se comunicam antes da saída.\n",
    "\n",
    "Nós podemos especificar o número de neurônios na camada como primeiro argumento, o método de inicialização como segundo argmento sendo ‘init’ e especificar a função de ativação utilizando o argumento ‘activation’.\n",
    "\n",
    "Neste caso, nós inicializamos o peso da rede para um pequeno número randômico gerado a partir de uma distribuição uniforme (‘uniform’), entre 0 e 0.05, nesse caso, porque esse é o peso padrão da distribuição uniforme no Keras. Uma alternativa tradicional seria o ‘normal’, gerando assim pequenos números randômicos a partir de uma distribuição gaussiana. Também será usada a função de ativação ‘relu’ nas primeiras duas camadas e a função sigmoide na camada de saída. O resultado deverá ser algo entre 0 e 1 com um threshold padrão de 0.5.\n",
    "\n",
    "Construindo o código, você pode notar que a primeira camada tem 12 neurônios e espera 8 variáveis de entrada. A segunda camada possui 8 neurônios e finalmente a saída tem 1 neurônio fazendo a predição da classe alvo (tendência a desenvolver diabetes ou não)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/matheusjerico/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/matheusjerico/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Cria o modelo\n",
    "model= Sequential()\n",
    "model.add(Dense(15, input_dim = 8, kernel_initializer = 'uniform', activation= 'relu'))\n",
    "model.add(Dense(12, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, kernel_initializer = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A compilação do modelo usa uma eficiente biblioteca numérica de backend, como Theano or TensorFlow. O backend automaticamente escolhe o melhor caminho para representar a rede e fazer predições.\n",
    "\n",
    "Será necessário em algum momento especificar a função de perda para avaliar os pesos. Nesse exemplo foi definido o uso da função de perda logarítmica, definido em Keras como “binary_crossentropy”. Também é utilizado o algoritmo Stochastic Gradient Descent para otimização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilando o modelo\n",
    "model.compile(loss= 'binary_crossentropy',\n",
    "              optimizer=SGD(lr = 0.01, momentum = 0.9, nesterov = True),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/matheusjerico/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheusjerico/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.6626 - acc: 0.6484\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 371us/step - loss: 0.6482 - acc: 0.6510\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 331us/step - loss: 0.6462 - acc: 0.6497\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 333us/step - loss: 0.6427 - acc: 0.6549\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 357us/step - loss: 0.6390 - acc: 0.6523\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 343us/step - loss: 0.6294 - acc: 0.6667\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 349us/step - loss: 0.6523 - acc: 0.6510\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 323us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 331us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 299us/step - loss: 0.6473 - acc: 0.6510\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.6495 - acc: 0.6510\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 295us/step - loss: 0.6473 - acc: 0.6510\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.6479 - acc: 0.6510\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 263us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 317us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 444us/step - loss: 0.6472 - acc: 0.6510\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 291us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 400us/step - loss: 0.6480 - acc: 0.6510\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 446us/step - loss: 0.6434 - acc: 0.6510\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 335us/step - loss: 0.6457 - acc: 0.6510\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 360us/step - loss: 0.6441 - acc: 0.6510\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 333us/step - loss: 0.6486 - acc: 0.6510\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 398us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 399us/step - loss: 0.6472 - acc: 0.6510\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 402us/step - loss: 0.6472 - acc: 0.6510\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 351us/step - loss: 0.6472 - acc: 0.6510\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 499us/step - loss: 0.6462 - acc: 0.6510\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 453us/step - loss: 0.6486 - acc: 0.6510\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 381us/step - loss: 0.6478 - acc: 0.6510\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 362us/step - loss: 0.6464 - acc: 0.6510\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 355us/step - loss: 0.6427 - acc: 0.6510\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 374us/step - loss: 0.6442 - acc: 0.6510\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 348us/step - loss: 0.6395 - acc: 0.6510\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 407us/step - loss: 0.6344 - acc: 0.6510\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s 356us/step - loss: 0.6499 - acc: 0.6510\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 427us/step - loss: 0.6477 - acc: 0.6510\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 407us/step - loss: 0.6484 - acc: 0.6497\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 449us/step - loss: 0.6421 - acc: 0.6458\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 444us/step - loss: 0.6353 - acc: 0.6641\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 384us/step - loss: 0.6479 - acc: 0.6523\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 366us/step - loss: 0.6476 - acc: 0.6602\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 374us/step - loss: 0.6481 - acc: 0.6510\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 408us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 361us/step - loss: 0.6483 - acc: 0.6510\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 400us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 392us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 489us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 464us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 423us/step - loss: 0.6473 - acc: 0.6510\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 415us/step - loss: 0.6480 - acc: 0.6510\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 485us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 500us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 377us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 331us/step - loss: 0.6482 - acc: 0.6510\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 370us/step - loss: 0.6479 - acc: 0.6510\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 366us/step - loss: 0.6477 - acc: 0.6510\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 472us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 516us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 444us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 486us/step - loss: 0.6479 - acc: 0.6510\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 457us/step - loss: 0.6472 - acc: 0.6510\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 474us/step - loss: 0.6473 - acc: 0.6510\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 542us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 408us/step - loss: 0.6473 - acc: 0.6510\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 498us/step - loss: 0.6473 - acc: 0.6510\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 400us/step - loss: 0.6471 - acc: 0.6510\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 427us/step - loss: 0.6480 - acc: 0.6510\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 487us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 414us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 473us/step - loss: 0.6479 - acc: 0.6510\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 521us/step - loss: 0.6477 - acc: 0.6510\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 445us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 373us/step - loss: 0.6473 - acc: 0.6510\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 318us/step - loss: 0.6483 - acc: 0.6510\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 371us/step - loss: 0.6470 - acc: 0.6510\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 370us/step - loss: 0.6477 - acc: 0.6510\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 343us/step - loss: 0.6478 - acc: 0.6510\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 404us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 300us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 372us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 545us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 560us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s 315us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 298us/step - loss: 0.6482 - acc: 0.6510\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 286us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 295us/step - loss: 0.6485 - acc: 0.6510\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 396us/step - loss: 0.6473 - acc: 0.6497\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 386us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 431us/step - loss: 0.6482 - acc: 0.6510\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 311us/step - loss: 0.6486 - acc: 0.6510\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.6481 - acc: 0.6510\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 258us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 269us/step - loss: 0.6470 - acc: 0.6510\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 295us/step - loss: 0.6476 - acc: 0.6523\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 252us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 505us/step - loss: 0.6477 - acc: 0.6510\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 522us/step - loss: 0.6484 - acc: 0.6510\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.6479 - acc: 0.6510\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 498us/step - loss: 0.6481 - acc: 0.6510\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 424us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 473us/step - loss: 0.6477 - acc: 0.6510\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 484us/step - loss: 0.6465 - acc: 0.6523\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 434us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 535us/step - loss: 0.6472 - acc: 0.6497\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 1s 663us/step - loss: 0.6474 - acc: 0.6523\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 582us/step - loss: 0.6471 - acc: 0.6510\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 368us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 268us/step - loss: 0.6481 - acc: 0.6510\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 291us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 320us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 367us/step - loss: 0.6480 - acc: 0.6510\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 457us/step - loss: 0.6473 - acc: 0.6510\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 422us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 270us/step - loss: 0.6486 - acc: 0.6510\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 306us/step - loss: 0.6467 - acc: 0.6523\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 321us/step - loss: 0.6481 - acc: 0.6510\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 274us/step - loss: 0.6472 - acc: 0.6510\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 258us/step - loss: 0.6482 - acc: 0.6510\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 271us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 254us/step - loss: 0.6474 - acc: 0.6523\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 438us/step - loss: 0.6479 - acc: 0.6497\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 410us/step - loss: 0.6477 - acc: 0.6510\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 522us/step - loss: 0.6479 - acc: 0.6510\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 397us/step - loss: 0.6480 - acc: 0.6510\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 430us/step - loss: 0.6470 - acc: 0.6510\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 317us/step - loss: 0.6470 - acc: 0.6510\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 365us/step - loss: 0.6481 - acc: 0.6510\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 400us/step - loss: 0.6463 - acc: 0.6536\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 440us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 380us/step - loss: 0.6466 - acc: 0.6510\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 292us/step - loss: 0.6480 - acc: 0.6510\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 406us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 317us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 248us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 310us/step - loss: 0.6472 - acc: 0.6510\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 262us/step - loss: 0.6471 - acc: 0.6523\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 194us/step - loss: 0.6471 - acc: 0.6536\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 397us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 404us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 427us/step - loss: 0.6472 - acc: 0.6510\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 303us/step - loss: 0.6466 - acc: 0.6510\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 323us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 259us/step - loss: 0.6473 - acc: 0.6523\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 327us/step - loss: 0.6465 - acc: 0.6523\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 347us/step - loss: 0.6474 - acc: 0.6523\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 311us/step - loss: 0.6468 - acc: 0.6536\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 286us/step - loss: 0.6471 - acc: 0.6523\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 339us/step - loss: 0.6479 - acc: 0.6523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc131dcadd8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executa o modelo e valida nos mesmo dados em que foi criado (Treino)\n",
    "model.fit(X, Y, nb_epoch=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compila o modelo com outro otimizador\n",
    "model.compile(loss= \"binary_crossentropy\",\n",
    "              optimizer= \"adam\",\n",
    "              metrics= [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheusjerico/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.6787 - acc: 0.6354\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 406us/step - loss: 0.6611 - acc: 0.6497\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 388us/step - loss: 0.6503 - acc: 0.6523\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 377us/step - loss: 0.6386 - acc: 0.6589\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 360us/step - loss: 0.6259 - acc: 0.6771\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 390us/step - loss: 0.6188 - acc: 0.6602\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 338us/step - loss: 0.6134 - acc: 0.6719\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 336us/step - loss: 0.6013 - acc: 0.6940\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 532us/step - loss: 0.5913 - acc: 0.6875\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 388us/step - loss: 0.5903 - acc: 0.7005\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 389us/step - loss: 0.5904 - acc: 0.6979\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 313us/step - loss: 0.5842 - acc: 0.6979\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 398us/step - loss: 0.5827 - acc: 0.6992\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 341us/step - loss: 0.5837 - acc: 0.6901\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 383us/step - loss: 0.5764 - acc: 0.6927\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 523us/step - loss: 0.5837 - acc: 0.6862\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 473us/step - loss: 0.5752 - acc: 0.6979\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 462us/step - loss: 0.5762 - acc: 0.7122\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 324us/step - loss: 0.5729 - acc: 0.6966\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 386us/step - loss: 0.5701 - acc: 0.7018\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 400us/step - loss: 0.5731 - acc: 0.7083\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 341us/step - loss: 0.5690 - acc: 0.7070\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 484us/step - loss: 0.5594 - acc: 0.7018\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 394us/step - loss: 0.5636 - acc: 0.7161\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 459us/step - loss: 0.5606 - acc: 0.7292\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 327us/step - loss: 0.5612 - acc: 0.7253\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 388us/step - loss: 0.5589 - acc: 0.7109\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 386us/step - loss: 0.5651 - acc: 0.7174\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 410us/step - loss: 0.5525 - acc: 0.7214\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 372us/step - loss: 0.5502 - acc: 0.7279\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 539us/step - loss: 0.5453 - acc: 0.7266\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 393us/step - loss: 0.5472 - acc: 0.7292\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 350us/step - loss: 0.5446 - acc: 0.7318\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 506us/step - loss: 0.5415 - acc: 0.7422\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 338us/step - loss: 0.5394 - acc: 0.7253\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s 313us/step - loss: 0.5384 - acc: 0.7396\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 363us/step - loss: 0.5383 - acc: 0.7435\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 390us/step - loss: 0.5315 - acc: 0.7409\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 420us/step - loss: 0.5347 - acc: 0.7474\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 337us/step - loss: 0.5276 - acc: 0.7422\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 489us/step - loss: 0.5299 - acc: 0.7474\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 496us/step - loss: 0.5234 - acc: 0.7409\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 458us/step - loss: 0.5199 - acc: 0.7487\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 480us/step - loss: 0.5200 - acc: 0.7461\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 403us/step - loss: 0.5233 - acc: 0.7487\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 421us/step - loss: 0.5146 - acc: 0.7565\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 352us/step - loss: 0.5233 - acc: 0.7383\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 475us/step - loss: 0.5168 - acc: 0.7500\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 441us/step - loss: 0.5130 - acc: 0.7539\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 538us/step - loss: 0.5039 - acc: 0.7526\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 340us/step - loss: 0.5133 - acc: 0.7565\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 351us/step - loss: 0.5015 - acc: 0.7643\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 380us/step - loss: 0.5125 - acc: 0.7604\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 490us/step - loss: 0.5018 - acc: 0.7500\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 420us/step - loss: 0.5127 - acc: 0.7513\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 394us/step - loss: 0.4993 - acc: 0.7617\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 392us/step - loss: 0.4974 - acc: 0.7565\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 385us/step - loss: 0.5000 - acc: 0.7552\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 349us/step - loss: 0.4981 - acc: 0.7591\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 381us/step - loss: 0.5003 - acc: 0.7513\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 381us/step - loss: 0.4913 - acc: 0.7721\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 379us/step - loss: 0.4946 - acc: 0.7643\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 369us/step - loss: 0.4910 - acc: 0.7526\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 433us/step - loss: 0.4962 - acc: 0.7630\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 406us/step - loss: 0.4879 - acc: 0.7591\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 534us/step - loss: 0.4912 - acc: 0.7747\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 446us/step - loss: 0.4937 - acc: 0.7747\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.5052 - acc: 0.759 - 0s 407us/step - loss: 0.4994 - acc: 0.7630\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 397us/step - loss: 0.4868 - acc: 0.7656\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 390us/step - loss: 0.4843 - acc: 0.7565\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 470us/step - loss: 0.4757 - acc: 0.7721\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 458us/step - loss: 0.4825 - acc: 0.7656\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 433us/step - loss: 0.4778 - acc: 0.7682\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 459us/step - loss: 0.4766 - acc: 0.7786\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 468us/step - loss: 0.4819 - acc: 0.7786\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 397us/step - loss: 0.4874 - acc: 0.7578\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 402us/step - loss: 0.4929 - acc: 0.7708\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 400us/step - loss: 0.4834 - acc: 0.7604\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 485us/step - loss: 0.4748 - acc: 0.7721\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 410us/step - loss: 0.4858 - acc: 0.7656\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 408us/step - loss: 0.4776 - acc: 0.7839\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 415us/step - loss: 0.4832 - acc: 0.7708\n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s 389us/step - loss: 0.4691 - acc: 0.7721\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s 361us/step - loss: 0.4754 - acc: 0.7878\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 371us/step - loss: 0.4714 - acc: 0.7865\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 378us/step - loss: 0.4808 - acc: 0.7721\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 351us/step - loss: 0.4703 - acc: 0.7656\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 377us/step - loss: 0.4640 - acc: 0.7891\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 342us/step - loss: 0.4669 - acc: 0.7799\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 324us/step - loss: 0.4616 - acc: 0.7878\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 377us/step - loss: 0.4577 - acc: 0.7813\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 342us/step - loss: 0.4645 - acc: 0.7786\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 335us/step - loss: 0.4608 - acc: 0.7760\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 341us/step - loss: 0.4625 - acc: 0.7799\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 339us/step - loss: 0.4662 - acc: 0.7669\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 362us/step - loss: 0.4690 - acc: 0.7734\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 332us/step - loss: 0.4562 - acc: 0.7917\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 379us/step - loss: 0.4564 - acc: 0.7865\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 368us/step - loss: 0.4521 - acc: 0.7956\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 357us/step - loss: 0.4591 - acc: 0.7878\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 341us/step - loss: 0.4538 - acc: 0.7930\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 374us/step - loss: 0.4533 - acc: 0.7865\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 381us/step - loss: 0.4519 - acc: 0.7969\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 350us/step - loss: 0.4580 - acc: 0.7760\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 375us/step - loss: 0.4593 - acc: 0.7799\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 379us/step - loss: 0.4512 - acc: 0.7930\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 343us/step - loss: 0.4508 - acc: 0.7891\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 394us/step - loss: 0.4598 - acc: 0.7839\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 370us/step - loss: 0.4493 - acc: 0.7852\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 336us/step - loss: 0.4542 - acc: 0.7786\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 364us/step - loss: 0.4509 - acc: 0.7799\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 336us/step - loss: 0.4524 - acc: 0.7826\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 382us/step - loss: 0.4521 - acc: 0.7799\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 370us/step - loss: 0.4475 - acc: 0.7865\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 338us/step - loss: 0.4427 - acc: 0.7930\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 367us/step - loss: 0.4436 - acc: 0.7786\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 379us/step - loss: 0.4459 - acc: 0.7956\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 341us/step - loss: 0.4393 - acc: 0.7812\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 380us/step - loss: 0.4444 - acc: 0.7812\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 395us/step - loss: 0.4442 - acc: 0.7917\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 403us/step - loss: 0.4450 - acc: 0.7852\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 335us/step - loss: 0.4445 - acc: 0.7904\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 358us/step - loss: 0.4483 - acc: 0.7865\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 358us/step - loss: 0.4388 - acc: 0.8034\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 379us/step - loss: 0.4363 - acc: 0.7852\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 441us/step - loss: 0.4393 - acc: 0.7943\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 521us/step - loss: 0.4379 - acc: 0.7878\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 384us/step - loss: 0.4356 - acc: 0.7852\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 402us/step - loss: 0.4351 - acc: 0.7982\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 433us/step - loss: 0.4340 - acc: 0.7917\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 335us/step - loss: 0.4430 - acc: 0.7930\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 377us/step - loss: 0.4398 - acc: 0.7865\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 452us/step - loss: 0.4457 - acc: 0.7826\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 360us/step - loss: 0.4364 - acc: 0.7917\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 403us/step - loss: 0.4435 - acc: 0.7969\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 375us/step - loss: 0.4329 - acc: 0.7917\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 332us/step - loss: 0.4359 - acc: 0.7917\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 393us/step - loss: 0.4254 - acc: 0.8008\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 409us/step - loss: 0.4349 - acc: 0.7956\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 393us/step - loss: 0.4429 - acc: 0.7969\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 365us/step - loss: 0.4284 - acc: 0.7917\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 395us/step - loss: 0.4290 - acc: 0.7943\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 408us/step - loss: 0.4337 - acc: 0.7956\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 521us/step - loss: 0.4277 - acc: 0.7982\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 484us/step - loss: 0.4417 - acc: 0.7878\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 419us/step - loss: 0.4325 - acc: 0.7878\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 433us/step - loss: 0.4248 - acc: 0.7878\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 371us/step - loss: 0.4306 - acc: 0.7891\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 439us/step - loss: 0.4324 - acc: 0.7904\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 486us/step - loss: 0.4327 - acc: 0.7891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a7b2d3a90>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, nb_epoch=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.04170761, -0.02752838, -0.1058771 ,  0.05580274, -0.00264212,\n",
       "          0.03636021,  0.02563382, -0.04601794,  0.01981658,  0.03272853,\n",
       "          0.03863087, -0.02132518],\n",
       "        [-0.2910543 , -0.05603553, -0.43336892,  0.0473329 , -0.03230176,\n",
       "         -0.01048775, -0.05020933, -0.04750825, -0.06187063,  0.00151781,\n",
       "         -0.02998345, -0.04433858],\n",
       "        [ 0.20954941, -0.06357262,  0.5850544 , -0.72439665, -0.09639756,\n",
       "         -0.04642153, -0.01398295, -0.03215681,  0.02863133, -0.16813119,\n",
       "         -0.01915523, -0.03920491],\n",
       "        [ 0.02764801, -0.02602398,  0.08884672, -0.14425543, -0.07769305,\n",
       "         -0.01939713,  0.00429885, -0.02297311,  0.04989242, -0.02846955,\n",
       "         -0.01463418,  0.01734216],\n",
       "        [-0.05017529,  0.01008849, -0.04569154,  0.04833099, -0.01370247,\n",
       "         -0.00773401, -0.00698298,  0.01515171, -0.01640523, -0.02835874,\n",
       "         -0.01835092, -0.02514972],\n",
       "        [ 0.03513693, -0.00412593,  0.02355562, -0.11481524, -0.06618693,\n",
       "          0.04742508, -0.046271  , -0.0281738 , -0.00168659, -0.06582052,\n",
       "         -0.02991822,  0.01195936],\n",
       "        [ 0.00355808,  0.03403351, -0.04764854, -0.02036991, -0.04807846,\n",
       "          0.04444131, -0.03427085,  0.04467359,  0.04319021, -0.02345883,\n",
       "         -0.04262542,  0.01649247],\n",
       "        [-0.05228937, -0.00720681, -0.04108014, -0.1466138 , -0.03164371,\n",
       "         -0.03782223,  0.03457402, -0.0280906 ,  0.00435603, -0.02847482,\n",
       "          0.04740545,  0.01088886]], dtype=float32),\n",
       " array([ 4.3742941e-03, -2.1094650e-04,  1.4773175e-02, -1.7585756e-02,\n",
       "        -1.4388839e-03, -2.7786380e-05, -6.2226172e-04,  0.0000000e+00,\n",
       "         9.4659039e-04, -2.7198521e-03, -2.9347457e-03,  0.0000000e+00],\n",
       "       dtype=float32),\n",
       " array([[-0.05723251, -0.0031855 , -0.00741188, -0.16766979, -0.09931076,\n",
       "         -0.0826282 , -0.06523495, -0.03268703],\n",
       "        [ 0.01433953,  0.0418441 , -0.01173873, -0.0065584 ,  0.04703268,\n",
       "         -0.03232991, -0.03765398,  0.01813808],\n",
       "        [-0.03701298, -0.02301603, -0.04031346, -0.10368403, -0.0647155 ,\n",
       "         -0.06708135, -0.02952529, -0.02789651],\n",
       "        [-0.04470248, -0.00482792, -0.0399119 , -0.20380014, -0.01436419,\n",
       "         -0.01858049, -0.01110309, -0.04372683],\n",
       "        [-0.00549516,  0.03600225, -0.02539722, -0.01358577,  0.00380319,\n",
       "         -0.00651445, -0.03837867, -0.04970454],\n",
       "        [-0.0417143 , -0.04788983, -0.03631048, -0.02934797,  0.02506135,\n",
       "         -0.0288963 , -0.00672037, -0.04814106],\n",
       "        [ 0.0046346 ,  0.02200653,  0.03919466, -0.01856797,  0.05523729,\n",
       "         -0.00579267, -0.05588396, -0.0341933 ],\n",
       "        [-0.01504164,  0.04607138, -0.01691832,  0.03627999,  0.03479279,\n",
       "          0.04828865,  0.04739057,  0.01404234],\n",
       "        [-0.03071301, -0.03354847, -0.03026798, -0.04280117, -0.04766736,\n",
       "         -0.02771829, -0.02314057, -0.04484288],\n",
       "        [-0.02683943, -0.01931677,  0.01434041, -0.03475433,  0.0501611 ,\n",
       "          0.04036068,  0.04677353, -0.01990316],\n",
       "        [-0.03126575,  0.00215263, -0.00673731,  0.01064835, -0.05062097,\n",
       "         -0.015465  , -0.00918833,  0.02853953],\n",
       "        [ 0.01198564,  0.01278966,  0.02027614, -0.01400858, -0.04471756,\n",
       "         -0.02804947, -0.03029709,  0.04882323]], dtype=float32),\n",
       " array([-0.00071624, -0.01039687, -0.00022787, -0.02400384, -0.05218055,\n",
       "        -0.04964697, -0.01414439, -0.00575882], dtype=float32),\n",
       " array([[ 0.00621489],\n",
       "        [-0.01339999],\n",
       "        [ 0.02436979],\n",
       "        [ 0.04732408],\n",
       "        [-0.04050162],\n",
       "        [-0.05118526],\n",
       "        [ 0.01763526],\n",
       "        [-0.05222099]], dtype=float32),\n",
       " array([-0.6253666], dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 263us/step\n",
      "acc: 77.34%\n"
     ]
    }
   ],
   "source": [
    "# Avaliar o resultado do modelo\n",
    "scores = model.evaluate(X,Y)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 514 samples, validate on 254 samples\n",
      "Epoch 1/150\n",
      "370/514 [====================>.........] - ETA: 0s - loss: 0.4693 - acc: 0.7622"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheusjerico/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 465us/step - loss: 0.4456 - acc: 0.7802 - val_loss: 0.3959 - val_acc: 0.8189\n",
      "Epoch 2/150\n",
      "514/514 [==============================] - 0s 407us/step - loss: 0.4395 - acc: 0.7782 - val_loss: 0.3913 - val_acc: 0.8189\n",
      "Epoch 3/150\n",
      "514/514 [==============================] - 0s 383us/step - loss: 0.4296 - acc: 0.7918 - val_loss: 0.4385 - val_acc: 0.8150\n",
      "Epoch 4/150\n",
      "514/514 [==============================] - 0s 423us/step - loss: 0.4329 - acc: 0.7802 - val_loss: 0.4378 - val_acc: 0.7953\n",
      "Epoch 5/150\n",
      "514/514 [==============================] - 0s 409us/step - loss: 0.4288 - acc: 0.7977 - val_loss: 0.4604 - val_acc: 0.8228\n",
      "Epoch 6/150\n",
      "514/514 [==============================] - 0s 479us/step - loss: 0.4335 - acc: 0.7821 - val_loss: 0.4381 - val_acc: 0.8228\n",
      "Epoch 7/150\n",
      "514/514 [==============================] - 0s 431us/step - loss: 0.4301 - acc: 0.7879 - val_loss: 0.4387 - val_acc: 0.8189\n",
      "Epoch 8/150\n",
      "514/514 [==============================] - 0s 447us/step - loss: 0.4365 - acc: 0.7802 - val_loss: 0.4317 - val_acc: 0.8346\n",
      "Epoch 9/150\n",
      "514/514 [==============================] - 0s 405us/step - loss: 0.4298 - acc: 0.7860 - val_loss: 0.4209 - val_acc: 0.8307\n",
      "Epoch 10/150\n",
      "514/514 [==============================] - 0s 444us/step - loss: 0.4208 - acc: 0.8035 - val_loss: 0.4322 - val_acc: 0.8110\n",
      "Epoch 11/150\n",
      "514/514 [==============================] - 0s 433us/step - loss: 0.4366 - acc: 0.7821 - val_loss: 0.4490 - val_acc: 0.8110\n",
      "Epoch 12/150\n",
      "514/514 [==============================] - 0s 394us/step - loss: 0.4264 - acc: 0.7821 - val_loss: 0.4342 - val_acc: 0.8228\n",
      "Epoch 13/150\n",
      "514/514 [==============================] - 0s 544us/step - loss: 0.4463 - acc: 0.7743 - val_loss: 0.4172 - val_acc: 0.8228\n",
      "Epoch 14/150\n",
      "514/514 [==============================] - 0s 502us/step - loss: 0.4280 - acc: 0.7938 - val_loss: 0.4144 - val_acc: 0.8110\n",
      "Epoch 15/150\n",
      "514/514 [==============================] - 0s 597us/step - loss: 0.4169 - acc: 0.8035 - val_loss: 0.4494 - val_acc: 0.8268\n",
      "Epoch 16/150\n",
      "514/514 [==============================] - 0s 422us/step - loss: 0.4290 - acc: 0.7996 - val_loss: 0.4138 - val_acc: 0.7953\n",
      "Epoch 17/150\n",
      "514/514 [==============================] - 0s 565us/step - loss: 0.4172 - acc: 0.7996 - val_loss: 0.4665 - val_acc: 0.7992\n",
      "Epoch 18/150\n",
      "514/514 [==============================] - 0s 523us/step - loss: 0.4287 - acc: 0.7899 - val_loss: 0.4594 - val_acc: 0.7835\n",
      "Epoch 19/150\n",
      "514/514 [==============================] - 0s 617us/step - loss: 0.4249 - acc: 0.7918 - val_loss: 0.4350 - val_acc: 0.8150\n",
      "Epoch 20/150\n",
      "514/514 [==============================] - 0s 399us/step - loss: 0.4224 - acc: 0.7977 - val_loss: 0.4245 - val_acc: 0.7992\n",
      "Epoch 21/150\n",
      "514/514 [==============================] - 0s 426us/step - loss: 0.4217 - acc: 0.8035 - val_loss: 0.4133 - val_acc: 0.8071\n",
      "Epoch 22/150\n",
      "514/514 [==============================] - 0s 493us/step - loss: 0.4272 - acc: 0.7938 - val_loss: 0.4246 - val_acc: 0.8110\n",
      "Epoch 23/150\n",
      "514/514 [==============================] - 0s 563us/step - loss: 0.4260 - acc: 0.7763 - val_loss: 0.4254 - val_acc: 0.8071\n",
      "Epoch 24/150\n",
      "514/514 [==============================] - 0s 444us/step - loss: 0.4152 - acc: 0.7957 - val_loss: 0.4228 - val_acc: 0.8189\n",
      "Epoch 25/150\n",
      "514/514 [==============================] - 0s 434us/step - loss: 0.4153 - acc: 0.7860 - val_loss: 0.4337 - val_acc: 0.8110\n",
      "Epoch 26/150\n",
      "514/514 [==============================] - 0s 628us/step - loss: 0.4213 - acc: 0.7782 - val_loss: 0.4462 - val_acc: 0.8189\n",
      "Epoch 27/150\n",
      "514/514 [==============================] - 0s 462us/step - loss: 0.4283 - acc: 0.8093 - val_loss: 0.4294 - val_acc: 0.8031\n",
      "Epoch 28/150\n",
      "514/514 [==============================] - 0s 433us/step - loss: 0.4208 - acc: 0.7918 - val_loss: 0.4163 - val_acc: 0.8071\n",
      "Epoch 29/150\n",
      "514/514 [==============================] - 0s 400us/step - loss: 0.4194 - acc: 0.7899 - val_loss: 0.4350 - val_acc: 0.8307\n",
      "Epoch 30/150\n",
      "514/514 [==============================] - 0s 374us/step - loss: 0.4107 - acc: 0.7840 - val_loss: 0.4389 - val_acc: 0.8268\n",
      "Epoch 31/150\n",
      "514/514 [==============================] - 0s 449us/step - loss: 0.4131 - acc: 0.7957 - val_loss: 0.4557 - val_acc: 0.8268\n",
      "Epoch 32/150\n",
      "514/514 [==============================] - 0s 539us/step - loss: 0.4172 - acc: 0.7840 - val_loss: 0.4406 - val_acc: 0.7795\n",
      "Epoch 33/150\n",
      "514/514 [==============================] - 0s 532us/step - loss: 0.4173 - acc: 0.7782 - val_loss: 0.4454 - val_acc: 0.8228\n",
      "Epoch 34/150\n",
      "514/514 [==============================] - 0s 519us/step - loss: 0.4185 - acc: 0.7938 - val_loss: 0.4184 - val_acc: 0.8071\n",
      "Epoch 35/150\n",
      "514/514 [==============================] - 0s 438us/step - loss: 0.4165 - acc: 0.7840 - val_loss: 0.4513 - val_acc: 0.7913\n",
      "Epoch 36/150\n",
      "514/514 [==============================] - 0s 520us/step - loss: 0.4120 - acc: 0.7918 - val_loss: 0.4518 - val_acc: 0.8228\n",
      "Epoch 37/150\n",
      "514/514 [==============================] - 0s 435us/step - loss: 0.4141 - acc: 0.7938 - val_loss: 0.4250 - val_acc: 0.8307\n",
      "Epoch 38/150\n",
      "514/514 [==============================] - 0s 540us/step - loss: 0.4293 - acc: 0.7899 - val_loss: 0.4721 - val_acc: 0.7992\n",
      "Epoch 39/150\n",
      "514/514 [==============================] - 0s 455us/step - loss: 0.4588 - acc: 0.7821 - val_loss: 0.4219 - val_acc: 0.8189\n",
      "Epoch 40/150\n",
      "514/514 [==============================] - 0s 545us/step - loss: 0.4159 - acc: 0.7938 - val_loss: 0.4317 - val_acc: 0.8150\n",
      "Epoch 41/150\n",
      "514/514 [==============================] - 0s 523us/step - loss: 0.4091 - acc: 0.7977 - val_loss: 0.4375 - val_acc: 0.8189\n",
      "Epoch 42/150\n",
      "514/514 [==============================] - 0s 530us/step - loss: 0.4102 - acc: 0.7957 - val_loss: 0.4509 - val_acc: 0.8150\n",
      "Epoch 43/150\n",
      "514/514 [==============================] - 0s 595us/step - loss: 0.4148 - acc: 0.7860 - val_loss: 0.4184 - val_acc: 0.7992\n",
      "Epoch 44/150\n",
      "514/514 [==============================] - 0s 686us/step - loss: 0.4191 - acc: 0.7938 - val_loss: 0.4402 - val_acc: 0.7874\n",
      "Epoch 45/150\n",
      "514/514 [==============================] - 0s 522us/step - loss: 0.4074 - acc: 0.8016 - val_loss: 0.4722 - val_acc: 0.8031\n",
      "Epoch 46/150\n",
      "514/514 [==============================] - 0s 527us/step - loss: 0.4169 - acc: 0.8074 - val_loss: 0.4649 - val_acc: 0.8346\n",
      "Epoch 47/150\n",
      "514/514 [==============================] - 0s 660us/step - loss: 0.4195 - acc: 0.7860 - val_loss: 0.4370 - val_acc: 0.7992\n",
      "Epoch 48/150\n",
      "514/514 [==============================] - 0s 552us/step - loss: 0.4093 - acc: 0.7977 - val_loss: 0.4421 - val_acc: 0.7953\n",
      "Epoch 49/150\n",
      "514/514 [==============================] - 0s 666us/step - loss: 0.4081 - acc: 0.8054 - val_loss: 0.4316 - val_acc: 0.8110\n",
      "Epoch 50/150\n",
      "514/514 [==============================] - 0s 673us/step - loss: 0.4084 - acc: 0.8074 - val_loss: 0.4073 - val_acc: 0.8150\n",
      "Epoch 51/150\n",
      "514/514 [==============================] - 0s 543us/step - loss: 0.4022 - acc: 0.8093 - val_loss: 0.4556 - val_acc: 0.7874\n",
      "Epoch 52/150\n",
      "514/514 [==============================] - 0s 647us/step - loss: 0.4176 - acc: 0.7840 - val_loss: 0.4319 - val_acc: 0.8150\n",
      "Epoch 53/150\n",
      "514/514 [==============================] - 0s 532us/step - loss: 0.4104 - acc: 0.8016 - val_loss: 0.4692 - val_acc: 0.7992\n",
      "Epoch 54/150\n",
      "514/514 [==============================] - 0s 540us/step - loss: 0.4064 - acc: 0.7957 - val_loss: 0.4921 - val_acc: 0.7992\n",
      "Epoch 55/150\n",
      "514/514 [==============================] - 0s 548us/step - loss: 0.4085 - acc: 0.7996 - val_loss: 0.4445 - val_acc: 0.8150\n",
      "Epoch 56/150\n",
      "514/514 [==============================] - 0s 529us/step - loss: 0.3982 - acc: 0.8093 - val_loss: 0.4626 - val_acc: 0.8150\n",
      "Epoch 57/150\n",
      "514/514 [==============================] - 0s 618us/step - loss: 0.4034 - acc: 0.8016 - val_loss: 0.4852 - val_acc: 0.7913\n",
      "Epoch 58/150\n",
      "514/514 [==============================] - 0s 505us/step - loss: 0.4221 - acc: 0.8113 - val_loss: 0.4452 - val_acc: 0.8150\n",
      "Epoch 59/150\n",
      "514/514 [==============================] - 0s 578us/step - loss: 0.4005 - acc: 0.8074 - val_loss: 0.4369 - val_acc: 0.8189\n",
      "Epoch 60/150\n",
      "514/514 [==============================] - 0s 533us/step - loss: 0.3988 - acc: 0.8074 - val_loss: 0.4278 - val_acc: 0.8110\n",
      "Epoch 61/150\n",
      "514/514 [==============================] - 0s 493us/step - loss: 0.4014 - acc: 0.8054 - val_loss: 0.4627 - val_acc: 0.8071\n",
      "Epoch 62/150\n",
      "514/514 [==============================] - 0s 514us/step - loss: 0.4127 - acc: 0.7977 - val_loss: 0.4365 - val_acc: 0.8071\n",
      "Epoch 63/150\n",
      "514/514 [==============================] - 0s 502us/step - loss: 0.3934 - acc: 0.8054 - val_loss: 0.4268 - val_acc: 0.8228\n",
      "Epoch 64/150\n",
      "514/514 [==============================] - 0s 497us/step - loss: 0.4073 - acc: 0.8054 - val_loss: 0.4141 - val_acc: 0.8150\n",
      "Epoch 65/150\n",
      "514/514 [==============================] - 0s 337us/step - loss: 0.4109 - acc: 0.7996 - val_loss: 0.4699 - val_acc: 0.7874\n",
      "Epoch 66/150\n",
      "514/514 [==============================] - 0s 764us/step - loss: 0.4061 - acc: 0.8074 - val_loss: 0.4628 - val_acc: 0.8228\n",
      "Epoch 67/150\n",
      "514/514 [==============================] - 0s 701us/step - loss: 0.4130 - acc: 0.8054 - val_loss: 0.4402 - val_acc: 0.8031\n",
      "Epoch 68/150\n",
      "514/514 [==============================] - 0s 679us/step - loss: 0.4001 - acc: 0.8074 - val_loss: 0.4442 - val_acc: 0.8150\n",
      "Epoch 69/150\n",
      "514/514 [==============================] - 0s 669us/step - loss: 0.3982 - acc: 0.7957 - val_loss: 0.4343 - val_acc: 0.8228\n",
      "Epoch 70/150\n",
      "514/514 [==============================] - 0s 674us/step - loss: 0.3915 - acc: 0.8230 - val_loss: 0.4757 - val_acc: 0.7874\n",
      "Epoch 71/150\n",
      "514/514 [==============================] - 0s 661us/step - loss: 0.4204 - acc: 0.7899 - val_loss: 0.4369 - val_acc: 0.8346\n",
      "Epoch 72/150\n",
      "514/514 [==============================] - 0s 753us/step - loss: 0.3955 - acc: 0.8093 - val_loss: 0.4476 - val_acc: 0.8031\n",
      "Epoch 73/150\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.4033 - acc: 0.8074 - val_loss: 0.4337 - val_acc: 0.7874\n",
      "Epoch 74/150\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.4007 - acc: 0.8113 - val_loss: 0.4992 - val_acc: 0.7638\n",
      "Epoch 75/150\n",
      "514/514 [==============================] - 0s 946us/step - loss: 0.4043 - acc: 0.8132 - val_loss: 0.4203 - val_acc: 0.7992\n",
      "Epoch 76/150\n",
      "514/514 [==============================] - 0s 782us/step - loss: 0.3901 - acc: 0.8054 - val_loss: 0.4233 - val_acc: 0.8071\n",
      "Epoch 77/150\n",
      "514/514 [==============================] - 0s 757us/step - loss: 0.3863 - acc: 0.8113 - val_loss: 0.4365 - val_acc: 0.7992\n",
      "Epoch 78/150\n",
      "514/514 [==============================] - 0s 950us/step - loss: 0.3940 - acc: 0.8171 - val_loss: 0.4342 - val_acc: 0.8150\n",
      "Epoch 79/150\n",
      "514/514 [==============================] - 0s 789us/step - loss: 0.3897 - acc: 0.8191 - val_loss: 0.4665 - val_acc: 0.8110\n",
      "Epoch 80/150\n",
      "514/514 [==============================] - 0s 795us/step - loss: 0.3980 - acc: 0.8113 - val_loss: 0.4447 - val_acc: 0.7953\n",
      "Epoch 81/150\n",
      "514/514 [==============================] - 0s 793us/step - loss: 0.3917 - acc: 0.7977 - val_loss: 0.4584 - val_acc: 0.8307\n",
      "Epoch 82/150\n",
      "514/514 [==============================] - 0s 925us/step - loss: 0.3920 - acc: 0.8016 - val_loss: 0.4882 - val_acc: 0.7992\n",
      "Epoch 83/150\n",
      "514/514 [==============================] - 0s 784us/step - loss: 0.3962 - acc: 0.7977 - val_loss: 0.4605 - val_acc: 0.8110\n",
      "Epoch 84/150\n",
      "514/514 [==============================] - 0s 767us/step - loss: 0.3972 - acc: 0.8230 - val_loss: 0.4511 - val_acc: 0.7953\n",
      "Epoch 85/150\n",
      "514/514 [==============================] - 0s 785us/step - loss: 0.4010 - acc: 0.8152 - val_loss: 0.4401 - val_acc: 0.7913\n",
      "Epoch 86/150\n",
      "514/514 [==============================] - 0s 822us/step - loss: 0.3891 - acc: 0.8016 - val_loss: 0.4617 - val_acc: 0.7992\n",
      "Epoch 87/150\n",
      "514/514 [==============================] - 0s 760us/step - loss: 0.4008 - acc: 0.7996 - val_loss: 0.4326 - val_acc: 0.8110\n",
      "Epoch 88/150\n",
      "514/514 [==============================] - 0s 769us/step - loss: 0.4020 - acc: 0.8054 - val_loss: 0.4461 - val_acc: 0.8071\n",
      "Epoch 89/150\n",
      "514/514 [==============================] - 0s 843us/step - loss: 0.3994 - acc: 0.8016 - val_loss: 0.4355 - val_acc: 0.8189\n",
      "Epoch 90/150\n",
      "514/514 [==============================] - 0s 843us/step - loss: 0.3924 - acc: 0.8132 - val_loss: 0.4733 - val_acc: 0.7953\n",
      "Epoch 91/150\n",
      "514/514 [==============================] - 0s 808us/step - loss: 0.3979 - acc: 0.8230 - val_loss: 0.5085 - val_acc: 0.7677\n",
      "Epoch 92/150\n",
      "514/514 [==============================] - 0s 828us/step - loss: 0.3965 - acc: 0.8093 - val_loss: 0.4477 - val_acc: 0.7992\n",
      "Epoch 93/150\n",
      "514/514 [==============================] - 0s 797us/step - loss: 0.4023 - acc: 0.7860 - val_loss: 0.4578 - val_acc: 0.8150\n",
      "Epoch 94/150\n",
      "514/514 [==============================] - 0s 841us/step - loss: 0.3938 - acc: 0.8152 - val_loss: 0.4754 - val_acc: 0.8110\n",
      "Epoch 95/150\n",
      "514/514 [==============================] - 0s 869us/step - loss: 0.3891 - acc: 0.8171 - val_loss: 0.4387 - val_acc: 0.8071\n",
      "Epoch 96/150\n",
      "514/514 [==============================] - 0s 761us/step - loss: 0.4034 - acc: 0.7957 - val_loss: 0.4453 - val_acc: 0.7992\n",
      "Epoch 97/150\n",
      "514/514 [==============================] - 0s 803us/step - loss: 0.3878 - acc: 0.8346 - val_loss: 0.4715 - val_acc: 0.7913\n",
      "Epoch 98/150\n",
      "514/514 [==============================] - 0s 805us/step - loss: 0.3879 - acc: 0.8054 - val_loss: 0.4544 - val_acc: 0.7913\n",
      "Epoch 99/150\n",
      "514/514 [==============================] - 0s 775us/step - loss: 0.3837 - acc: 0.8074 - val_loss: 0.4960 - val_acc: 0.7953\n",
      "Epoch 100/150\n",
      "514/514 [==============================] - 0s 855us/step - loss: 0.4216 - acc: 0.8016 - val_loss: 0.4929 - val_acc: 0.7953\n",
      "Epoch 101/150\n",
      "514/514 [==============================] - 0s 796us/step - loss: 0.3994 - acc: 0.7957 - val_loss: 0.4347 - val_acc: 0.8110\n",
      "Epoch 102/150\n",
      "514/514 [==============================] - 0s 783us/step - loss: 0.3857 - acc: 0.8074 - val_loss: 0.4432 - val_acc: 0.8031\n",
      "Epoch 103/150\n",
      "514/514 [==============================] - 0s 690us/step - loss: 0.3785 - acc: 0.8191 - val_loss: 0.4843 - val_acc: 0.8031\n",
      "Epoch 104/150\n",
      "514/514 [==============================] - 0s 771us/step - loss: 0.3964 - acc: 0.8074 - val_loss: 0.4342 - val_acc: 0.8189\n",
      "Epoch 105/150\n",
      "514/514 [==============================] - 0s 880us/step - loss: 0.3896 - acc: 0.8171 - val_loss: 0.4577 - val_acc: 0.8228\n",
      "Epoch 106/150\n",
      "514/514 [==============================] - 0s 781us/step - loss: 0.3819 - acc: 0.7957 - val_loss: 0.4517 - val_acc: 0.7953\n",
      "Epoch 107/150\n",
      "514/514 [==============================] - 0s 742us/step - loss: 0.3853 - acc: 0.8210 - val_loss: 0.4740 - val_acc: 0.7913\n",
      "Epoch 108/150\n",
      "514/514 [==============================] - 0s 780us/step - loss: 0.3806 - acc: 0.8230 - val_loss: 0.4292 - val_acc: 0.8071\n",
      "Epoch 109/150\n",
      "514/514 [==============================] - 0s 903us/step - loss: 0.3765 - acc: 0.8171 - val_loss: 0.4622 - val_acc: 0.7953\n",
      "Epoch 110/150\n",
      "514/514 [==============================] - 0s 816us/step - loss: 0.3785 - acc: 0.8152 - val_loss: 0.4248 - val_acc: 0.8071\n",
      "Epoch 111/150\n",
      "514/514 [==============================] - 0s 854us/step - loss: 0.3788 - acc: 0.8210 - val_loss: 0.4804 - val_acc: 0.8071\n",
      "Epoch 112/150\n",
      "514/514 [==============================] - 0s 791us/step - loss: 0.3794 - acc: 0.8249 - val_loss: 0.4763 - val_acc: 0.8189\n",
      "Epoch 113/150\n",
      "514/514 [==============================] - 0s 895us/step - loss: 0.3876 - acc: 0.8093 - val_loss: 0.4612 - val_acc: 0.7992\n",
      "Epoch 114/150\n",
      "514/514 [==============================] - 0s 836us/step - loss: 0.3851 - acc: 0.8035 - val_loss: 0.4682 - val_acc: 0.8031\n",
      "Epoch 115/150\n",
      "514/514 [==============================] - 0s 718us/step - loss: 0.3940 - acc: 0.7996 - val_loss: 0.4524 - val_acc: 0.7874\n",
      "Epoch 116/150\n",
      "514/514 [==============================] - 0s 889us/step - loss: 0.3940 - acc: 0.8054 - val_loss: 0.4508 - val_acc: 0.7913\n",
      "Epoch 117/150\n",
      "514/514 [==============================] - 0s 780us/step - loss: 0.3773 - acc: 0.8171 - val_loss: 0.5114 - val_acc: 0.7953\n",
      "Epoch 118/150\n",
      "514/514 [==============================] - 0s 897us/step - loss: 0.3832 - acc: 0.8230 - val_loss: 0.4547 - val_acc: 0.7992\n",
      "Epoch 119/150\n",
      "514/514 [==============================] - 0s 781us/step - loss: 0.3766 - acc: 0.8171 - val_loss: 0.4371 - val_acc: 0.8031\n",
      "Epoch 120/150\n",
      "514/514 [==============================] - 0s 785us/step - loss: 0.3809 - acc: 0.8171 - val_loss: 0.4573 - val_acc: 0.8071\n",
      "Epoch 121/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 747us/step - loss: 0.3752 - acc: 0.8191 - val_loss: 0.4368 - val_acc: 0.7953\n",
      "Epoch 122/150\n",
      "514/514 [==============================] - 0s 603us/step - loss: 0.3887 - acc: 0.8152 - val_loss: 0.4617 - val_acc: 0.8150\n",
      "Epoch 123/150\n",
      "514/514 [==============================] - 0s 701us/step - loss: 0.3865 - acc: 0.8210 - val_loss: 0.4443 - val_acc: 0.8150\n",
      "Epoch 124/150\n",
      "514/514 [==============================] - 0s 757us/step - loss: 0.3934 - acc: 0.8152 - val_loss: 0.4727 - val_acc: 0.7953\n",
      "Epoch 125/150\n",
      "514/514 [==============================] - 0s 761us/step - loss: 0.3852 - acc: 0.8016 - val_loss: 0.4403 - val_acc: 0.8071\n",
      "Epoch 126/150\n",
      "514/514 [==============================] - 0s 774us/step - loss: 0.3881 - acc: 0.8210 - val_loss: 0.5175 - val_acc: 0.7756\n",
      "Epoch 127/150\n",
      "514/514 [==============================] - 0s 725us/step - loss: 0.3927 - acc: 0.8035 - val_loss: 0.4639 - val_acc: 0.7953\n",
      "Epoch 128/150\n",
      "514/514 [==============================] - 0s 693us/step - loss: 0.3888 - acc: 0.8191 - val_loss: 0.4865 - val_acc: 0.7992\n",
      "Epoch 129/150\n",
      "514/514 [==============================] - 0s 774us/step - loss: 0.3985 - acc: 0.8035 - val_loss: 0.4504 - val_acc: 0.8071\n",
      "Epoch 130/150\n",
      "514/514 [==============================] - 0s 864us/step - loss: 0.3687 - acc: 0.8288 - val_loss: 0.4388 - val_acc: 0.8031\n",
      "Epoch 131/150\n",
      "514/514 [==============================] - 0s 875us/step - loss: 0.3802 - acc: 0.8171 - val_loss: 0.4966 - val_acc: 0.7874\n",
      "Epoch 132/150\n",
      "514/514 [==============================] - 0s 712us/step - loss: 0.3791 - acc: 0.8132 - val_loss: 0.4861 - val_acc: 0.8150\n",
      "Epoch 133/150\n",
      "514/514 [==============================] - 0s 677us/step - loss: 0.3860 - acc: 0.8230 - val_loss: 0.4462 - val_acc: 0.8150\n",
      "Epoch 134/150\n",
      "514/514 [==============================] - 0s 758us/step - loss: 0.3701 - acc: 0.8230 - val_loss: 0.4377 - val_acc: 0.7835\n",
      "Epoch 135/150\n",
      "514/514 [==============================] - 0s 668us/step - loss: 0.3779 - acc: 0.8191 - val_loss: 0.4462 - val_acc: 0.7992\n",
      "Epoch 136/150\n",
      "514/514 [==============================] - 0s 785us/step - loss: 0.3757 - acc: 0.8249 - val_loss: 0.4509 - val_acc: 0.7992\n",
      "Epoch 137/150\n",
      "514/514 [==============================] - 0s 801us/step - loss: 0.3780 - acc: 0.8113 - val_loss: 0.4383 - val_acc: 0.7953\n",
      "Epoch 138/150\n",
      "514/514 [==============================] - 0s 787us/step - loss: 0.3693 - acc: 0.8210 - val_loss: 0.4592 - val_acc: 0.7835\n",
      "Epoch 139/150\n",
      "514/514 [==============================] - 0s 836us/step - loss: 0.3901 - acc: 0.8074 - val_loss: 0.4956 - val_acc: 0.7795\n",
      "Epoch 140/150\n",
      "514/514 [==============================] - 0s 780us/step - loss: 0.3841 - acc: 0.7977 - val_loss: 0.4585 - val_acc: 0.8110\n",
      "Epoch 141/150\n",
      "514/514 [==============================] - 0s 810us/step - loss: 0.4088 - acc: 0.8016 - val_loss: 0.4566 - val_acc: 0.8071\n",
      "Epoch 142/150\n",
      "514/514 [==============================] - 0s 798us/step - loss: 0.3781 - acc: 0.8171 - val_loss: 0.5181 - val_acc: 0.7835\n",
      "Epoch 143/150\n",
      "514/514 [==============================] - 0s 807us/step - loss: 0.3775 - acc: 0.8191 - val_loss: 0.4435 - val_acc: 0.8150\n",
      "Epoch 144/150\n",
      "514/514 [==============================] - 0s 756us/step - loss: 0.3773 - acc: 0.8249 - val_loss: 0.4696 - val_acc: 0.7874\n",
      "Epoch 145/150\n",
      "514/514 [==============================] - 0s 921us/step - loss: 0.3723 - acc: 0.8346 - val_loss: 0.4973 - val_acc: 0.8031\n",
      "Epoch 146/150\n",
      "514/514 [==============================] - 0s 761us/step - loss: 0.3747 - acc: 0.8171 - val_loss: 0.4385 - val_acc: 0.7992\n",
      "Epoch 147/150\n",
      "514/514 [==============================] - 0s 779us/step - loss: 0.3728 - acc: 0.8210 - val_loss: 0.4738 - val_acc: 0.7835\n",
      "Epoch 148/150\n",
      "514/514 [==============================] - 0s 810us/step - loss: 0.3801 - acc: 0.8249 - val_loss: 0.4435 - val_acc: 0.8071\n",
      "Epoch 149/150\n",
      "514/514 [==============================] - 0s 721us/step - loss: 0.3838 - acc: 0.8191 - val_loss: 0.4962 - val_acc: 0.7756\n",
      "Epoch 150/150\n",
      "514/514 [==============================] - 0s 804us/step - loss: 0.3869 - acc: 0.7996 - val_loss: 0.4433 - val_acc: 0.7913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a734e9ba8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executa o modelo e faz validação em um conjunto de dados separados automaticamente para testes\n",
    "model.fit(X,Y, validation_split=0.33, nb_epoch=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 537 samples, validate on 231 samples\n",
      "Epoch 1/150\n",
      "420/537 [======================>.......] - ETA: 0s - loss: 0.6342 - acc: 0.6714"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheusjerico/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 664us/step - loss: 0.6435 - acc: 0.6574 - val_loss: 0.6568 - val_acc: 0.6364\n",
      "Epoch 2/150\n",
      "537/537 [==============================] - 0s 405us/step - loss: 0.6432 - acc: 0.6574 - val_loss: 0.6563 - val_acc: 0.6364\n",
      "Epoch 3/150\n",
      "537/537 [==============================] - 0s 401us/step - loss: 0.6433 - acc: 0.6574 - val_loss: 0.6565 - val_acc: 0.6364\n",
      "Epoch 4/150\n",
      "537/537 [==============================] - 0s 403us/step - loss: 0.6431 - acc: 0.6574 - val_loss: 0.6568 - val_acc: 0.6364\n",
      "Epoch 5/150\n",
      "537/537 [==============================] - 0s 419us/step - loss: 0.6430 - acc: 0.6574 - val_loss: 0.6562 - val_acc: 0.6364\n",
      "Epoch 6/150\n",
      "537/537 [==============================] - 0s 406us/step - loss: 0.6443 - acc: 0.6574 - val_loss: 0.6559 - val_acc: 0.6364\n",
      "Epoch 7/150\n",
      "537/537 [==============================] - 0s 415us/step - loss: 0.6451 - acc: 0.6574 - val_loss: 0.6564 - val_acc: 0.6364\n",
      "Epoch 8/150\n",
      "537/537 [==============================] - 0s 416us/step - loss: 0.6430 - acc: 0.6574 - val_loss: 0.6564 - val_acc: 0.6364\n",
      "Epoch 9/150\n",
      "537/537 [==============================] - 0s 484us/step - loss: 0.6436 - acc: 0.6574 - val_loss: 0.6566 - val_acc: 0.6364\n",
      "Epoch 10/150\n",
      "537/537 [==============================] - 0s 534us/step - loss: 0.6430 - acc: 0.6574 - val_loss: 0.6562 - val_acc: 0.6364\n",
      "Epoch 11/150\n",
      "537/537 [==============================] - 0s 472us/step - loss: 0.6437 - acc: 0.6574 - val_loss: 0.6561 - val_acc: 0.6364\n",
      "Epoch 12/150\n",
      "537/537 [==============================] - 0s 495us/step - loss: 0.6430 - acc: 0.6574 - val_loss: 0.6570 - val_acc: 0.6364\n",
      "Epoch 13/150\n",
      "537/537 [==============================] - 0s 413us/step - loss: 0.6439 - acc: 0.6574 - val_loss: 0.6563 - val_acc: 0.6364\n",
      "Epoch 14/150\n",
      "537/537 [==============================] - 0s 474us/step - loss: 0.6433 - acc: 0.6574 - val_loss: 0.6563 - val_acc: 0.6364\n",
      "Epoch 15/150\n",
      "537/537 [==============================] - 0s 434us/step - loss: 0.6434 - acc: 0.6574 - val_loss: 0.6564 - val_acc: 0.6364\n",
      "Epoch 16/150\n",
      "537/537 [==============================] - 0s 618us/step - loss: 0.6448 - acc: 0.6592 - val_loss: 0.6568 - val_acc: 0.6364\n",
      "Epoch 17/150\n",
      "537/537 [==============================] - 0s 490us/step - loss: 0.6415 - acc: 0.6592 - val_loss: 0.6572 - val_acc: 0.6364\n",
      "Epoch 18/150\n",
      "537/537 [==============================] - 0s 415us/step - loss: 0.6413 - acc: 0.6592 - val_loss: 0.6566 - val_acc: 0.6364\n",
      "Epoch 19/150\n",
      "537/537 [==============================] - 0s 546us/step - loss: 0.6440 - acc: 0.6555 - val_loss: 0.6564 - val_acc: 0.6364\n",
      "Epoch 20/150\n",
      "537/537 [==============================] - 0s 587us/step - loss: 0.6419 - acc: 0.6574 - val_loss: 0.6567 - val_acc: 0.6364\n",
      "Epoch 21/150\n",
      "537/537 [==============================] - 0s 399us/step - loss: 0.6432 - acc: 0.6574 - val_loss: 0.6566 - val_acc: 0.6364\n",
      "Epoch 22/150\n",
      "537/537 [==============================] - 0s 429us/step - loss: 0.6411 - acc: 0.6592 - val_loss: 0.6570 - val_acc: 0.6364\n",
      "Epoch 23/150\n",
      "537/537 [==============================] - 0s 610us/step - loss: 0.6431 - acc: 0.6574 - val_loss: 0.6568 - val_acc: 0.6364\n",
      "Epoch 24/150\n",
      "537/537 [==============================] - 0s 401us/step - loss: 0.6414 - acc: 0.6574 - val_loss: 0.6564 - val_acc: 0.6364\n",
      "Epoch 25/150\n",
      "537/537 [==============================] - 0s 504us/step - loss: 0.6413 - acc: 0.6574 - val_loss: 0.6564 - val_acc: 0.6364\n",
      "Epoch 26/150\n",
      "537/537 [==============================] - 0s 417us/step - loss: 0.6415 - acc: 0.6592 - val_loss: 0.6561 - val_acc: 0.6364\n",
      "Epoch 27/150\n",
      "537/537 [==============================] - 0s 552us/step - loss: 0.6410 - acc: 0.6592 - val_loss: 0.6562 - val_acc: 0.6364\n",
      "Epoch 28/150\n",
      "537/537 [==============================] - 0s 611us/step - loss: 0.6433 - acc: 0.6574 - val_loss: 0.6563 - val_acc: 0.6364\n",
      "Epoch 29/150\n",
      "537/537 [==============================] - 0s 565us/step - loss: 0.6418 - acc: 0.6592 - val_loss: 0.6569 - val_acc: 0.6364\n",
      "Epoch 30/150\n",
      "537/537 [==============================] - 0s 602us/step - loss: 0.6418 - acc: 0.6574 - val_loss: 0.6567 - val_acc: 0.6364\n",
      "Epoch 31/150\n",
      "537/537 [==============================] - 0s 426us/step - loss: 0.6438 - acc: 0.6574 - val_loss: 0.6562 - val_acc: 0.6364\n",
      "Epoch 32/150\n",
      "537/537 [==============================] - 0s 453us/step - loss: 0.6426 - acc: 0.6574 - val_loss: 0.6565 - val_acc: 0.6364\n",
      "Epoch 33/150\n",
      "537/537 [==============================] - 0s 445us/step - loss: 0.6415 - acc: 0.6592 - val_loss: 0.6565 - val_acc: 0.6364\n",
      "Epoch 34/150\n",
      "537/537 [==============================] - 0s 443us/step - loss: 0.6396 - acc: 0.6611 - val_loss: 0.6569 - val_acc: 0.6364\n",
      "Epoch 35/150\n",
      "537/537 [==============================] - 0s 479us/step - loss: 0.6420 - acc: 0.6592 - val_loss: 0.6573 - val_acc: 0.6364\n",
      "Epoch 36/150\n",
      "537/537 [==============================] - 0s 516us/step - loss: 0.6414 - acc: 0.6592 - val_loss: 0.6562 - val_acc: 0.6364\n",
      "Epoch 37/150\n",
      "537/537 [==============================] - 0s 469us/step - loss: 0.6421 - acc: 0.6592 - val_loss: 0.6564 - val_acc: 0.6364\n",
      "Epoch 38/150\n",
      "537/537 [==============================] - 0s 423us/step - loss: 0.6425 - acc: 0.6574 - val_loss: 0.6561 - val_acc: 0.6364\n",
      "Epoch 39/150\n",
      "537/537 [==============================] - 0s 452us/step - loss: 0.6408 - acc: 0.6574 - val_loss: 0.6564 - val_acc: 0.6364\n",
      "Epoch 40/150\n",
      "537/537 [==============================] - 0s 381us/step - loss: 0.6422 - acc: 0.6592 - val_loss: 0.6567 - val_acc: 0.6364\n",
      "Epoch 41/150\n",
      "537/537 [==============================] - 0s 650us/step - loss: 0.6423 - acc: 0.6574 - val_loss: 0.6565 - val_acc: 0.6364\n",
      "Epoch 42/150\n",
      "537/537 [==============================] - 0s 386us/step - loss: 0.6408 - acc: 0.6592 - val_loss: 0.6569 - val_acc: 0.6364\n",
      "Epoch 43/150\n",
      "537/537 [==============================] - 0s 379us/step - loss: 0.6418 - acc: 0.6574 - val_loss: 0.6569 - val_acc: 0.6364\n",
      "Epoch 44/150\n",
      "537/537 [==============================] - 0s 402us/step - loss: 0.6410 - acc: 0.6592 - val_loss: 0.6560 - val_acc: 0.6364\n",
      "Epoch 45/150\n",
      "537/537 [==============================] - 0s 391us/step - loss: 0.6434 - acc: 0.6592 - val_loss: 0.6563 - val_acc: 0.6364\n",
      "Epoch 46/150\n",
      "537/537 [==============================] - 0s 398us/step - loss: 0.6437 - acc: 0.6555 - val_loss: 0.6563 - val_acc: 0.6364\n",
      "Epoch 47/150\n",
      "537/537 [==============================] - 0s 406us/step - loss: 0.6397 - acc: 0.6611 - val_loss: 0.6569 - val_acc: 0.6364\n",
      "Epoch 48/150\n",
      "537/537 [==============================] - 0s 372us/step - loss: 0.6410 - acc: 0.6592 - val_loss: 0.6562 - val_acc: 0.6364\n",
      "Epoch 49/150\n",
      "537/537 [==============================] - 0s 470us/step - loss: 0.6426 - acc: 0.6574 - val_loss: 0.6570 - val_acc: 0.6364\n",
      "Epoch 50/150\n",
      "537/537 [==============================] - 0s 407us/step - loss: 0.6426 - acc: 0.6574 - val_loss: 0.6569 - val_acc: 0.6364\n",
      "Epoch 51/150\n",
      "537/537 [==============================] - 0s 407us/step - loss: 0.6423 - acc: 0.6574 - val_loss: 0.6563 - val_acc: 0.6364\n",
      "Epoch 52/150\n",
      "537/537 [==============================] - 0s 365us/step - loss: 0.6418 - acc: 0.6592 - val_loss: 0.6561 - val_acc: 0.6364\n",
      "Epoch 53/150\n",
      "537/537 [==============================] - 0s 519us/step - loss: 0.6414 - acc: 0.6592 - val_loss: 0.6568 - val_acc: 0.6364\n",
      "Epoch 54/150\n",
      "537/537 [==============================] - 0s 666us/step - loss: 0.6422 - acc: 0.6574 - val_loss: 0.6571 - val_acc: 0.6364\n",
      "Epoch 55/150\n",
      "537/537 [==============================] - 0s 429us/step - loss: 0.6456 - acc: 0.6574 - val_loss: 0.6558 - val_acc: 0.6364\n",
      "Epoch 56/150\n",
      "537/537 [==============================] - 0s 409us/step - loss: 0.6422 - acc: 0.6592 - val_loss: 0.6561 - val_acc: 0.6364\n",
      "Epoch 57/150\n",
      "537/537 [==============================] - 0s 402us/step - loss: 0.6414 - acc: 0.6592 - val_loss: 0.6561 - val_acc: 0.6364\n",
      "Epoch 58/150\n",
      "537/537 [==============================] - 0s 510us/step - loss: 0.6400 - acc: 0.6611 - val_loss: 0.6567 - val_acc: 0.6364\n",
      "Epoch 59/150\n",
      "537/537 [==============================] - 0s 411us/step - loss: 0.6450 - acc: 0.6555 - val_loss: 0.6574 - val_acc: 0.6364\n",
      "Epoch 60/150\n",
      "537/537 [==============================] - 0s 470us/step - loss: 0.6431 - acc: 0.6574 - val_loss: 0.6560 - val_acc: 0.6364\n",
      "Epoch 61/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 430us/step - loss: 0.6409 - acc: 0.6574 - val_loss: 0.6565 - val_acc: 0.6364\n",
      "Epoch 62/150\n",
      "537/537 [==============================] - 0s 485us/step - loss: 0.6414 - acc: 0.6574 - val_loss: 0.6566 - val_acc: 0.6364\n",
      "Epoch 63/150\n",
      "537/537 [==============================] - 0s 425us/step - loss: 0.6428 - acc: 0.6574 - val_loss: 0.6565 - val_acc: 0.6364\n",
      "Epoch 64/150\n",
      "537/537 [==============================] - 0s 428us/step - loss: 0.6400 - acc: 0.6611 - val_loss: 0.6560 - val_acc: 0.6364\n",
      "Epoch 65/150\n",
      "537/537 [==============================] - 0s 391us/step - loss: 0.6428 - acc: 0.6574 - val_loss: 0.6564 - val_acc: 0.6364\n",
      "Epoch 66/150\n",
      "537/537 [==============================] - 0s 398us/step - loss: 0.6412 - acc: 0.6611 - val_loss: 0.6564 - val_acc: 0.6364\n",
      "Epoch 67/150\n",
      "537/537 [==============================] - 0s 421us/step - loss: 0.6399 - acc: 0.6611 - val_loss: 0.6563 - val_acc: 0.6364\n",
      "Epoch 68/150\n",
      "537/537 [==============================] - 0s 426us/step - loss: 0.6407 - acc: 0.6592 - val_loss: 0.6559 - val_acc: 0.6364\n",
      "Epoch 69/150\n",
      "537/537 [==============================] - 0s 498us/step - loss: 0.6421 - acc: 0.6592 - val_loss: 0.6563 - val_acc: 0.6364\n",
      "Epoch 70/150\n",
      "537/537 [==============================] - 0s 484us/step - loss: 0.6446 - acc: 0.6555 - val_loss: 0.6564 - val_acc: 0.6364\n",
      "Epoch 71/150\n",
      "537/537 [==============================] - 0s 518us/step - loss: 0.6428 - acc: 0.6574 - val_loss: 0.6563 - val_acc: 0.6364\n",
      "Epoch 72/150\n",
      "537/537 [==============================] - 0s 472us/step - loss: 0.6411 - acc: 0.6611 - val_loss: 0.6573 - val_acc: 0.6364\n",
      "Epoch 73/150\n",
      "537/537 [==============================] - 0s 448us/step - loss: 0.6399 - acc: 0.6611 - val_loss: 0.6565 - val_acc: 0.6364\n",
      "Epoch 74/150\n",
      "537/537 [==============================] - 0s 407us/step - loss: 0.6422 - acc: 0.6592 - val_loss: 0.6571 - val_acc: 0.6364\n",
      "Epoch 75/150\n",
      "537/537 [==============================] - 0s 467us/step - loss: 0.6462 - acc: 0.6536 - val_loss: 0.6567 - val_acc: 0.6364\n",
      "Epoch 76/150\n",
      "537/537 [==============================] - 0s 494us/step - loss: 0.6408 - acc: 0.6592 - val_loss: 0.6566 - val_acc: 0.6364\n",
      "Epoch 77/150\n",
      "537/537 [==============================] - 0s 466us/step - loss: 0.6405 - acc: 0.6592 - val_loss: 0.6568 - val_acc: 0.6364\n",
      "Epoch 78/150\n",
      "537/537 [==============================] - 0s 469us/step - loss: 0.6427 - acc: 0.6574 - val_loss: 0.6561 - val_acc: 0.6364\n",
      "Epoch 79/150\n",
      "537/537 [==============================] - 0s 494us/step - loss: 0.6419 - acc: 0.6592 - val_loss: 0.6573 - val_acc: 0.6364\n",
      "Epoch 80/150\n",
      "537/537 [==============================] - 0s 494us/step - loss: 0.6393 - acc: 0.6611 - val_loss: 0.6563 - val_acc: 0.6364\n",
      "Epoch 81/150\n",
      "537/537 [==============================] - 0s 508us/step - loss: 0.6428 - acc: 0.6574 - val_loss: 0.6567 - val_acc: 0.6364\n",
      "Epoch 82/150\n",
      "537/537 [==============================] - 0s 474us/step - loss: 0.6408 - acc: 0.6592 - val_loss: 0.6567 - val_acc: 0.6364\n",
      "Epoch 83/150\n",
      "537/537 [==============================] - 0s 500us/step - loss: 0.6442 - acc: 0.6555 - val_loss: 0.6563 - val_acc: 0.6364\n",
      "Epoch 84/150\n",
      "537/537 [==============================] - 0s 514us/step - loss: 0.6427 - acc: 0.6574 - val_loss: 0.6561 - val_acc: 0.6364\n",
      "Epoch 85/150\n",
      "537/537 [==============================] - 0s 462us/step - loss: 0.6417 - acc: 0.6574 - val_loss: 0.6564 - val_acc: 0.6364\n",
      "Epoch 86/150\n",
      "537/537 [==============================] - 0s 508us/step - loss: 0.6400 - acc: 0.6611 - val_loss: 0.6572 - val_acc: 0.6364\n",
      "Epoch 87/150\n",
      "537/537 [==============================] - 0s 495us/step - loss: 0.6404 - acc: 0.6592 - val_loss: 0.6566 - val_acc: 0.6364\n",
      "Epoch 88/150\n",
      "537/537 [==============================] - 0s 483us/step - loss: 0.6392 - acc: 0.6611 - val_loss: 0.6571 - val_acc: 0.6364\n",
      "Epoch 89/150\n",
      "537/537 [==============================] - 0s 495us/step - loss: 0.6430 - acc: 0.6574 - val_loss: 0.6567 - val_acc: 0.6364\n",
      "Epoch 90/150\n",
      "537/537 [==============================] - 0s 482us/step - loss: 0.6417 - acc: 0.6592 - val_loss: 0.6571 - val_acc: 0.6364\n",
      "Epoch 91/150\n",
      "537/537 [==============================] - 0s 499us/step - loss: 0.6406 - acc: 0.6592 - val_loss: 0.6569 - val_acc: 0.6364\n",
      "Epoch 92/150\n",
      "537/537 [==============================] - 0s 559us/step - loss: 0.6406 - acc: 0.6592 - val_loss: 0.6563 - val_acc: 0.6364\n",
      "Epoch 93/150\n",
      "537/537 [==============================] - 0s 507us/step - loss: 0.6408 - acc: 0.6592 - val_loss: 0.6567 - val_acc: 0.6364\n",
      "Epoch 94/150\n",
      "537/537 [==============================] - 0s 474us/step - loss: 0.6410 - acc: 0.6611 - val_loss: 0.6566 - val_acc: 0.6364\n",
      "Epoch 95/150\n",
      "537/537 [==============================] - 0s 518us/step - loss: 0.6397 - acc: 0.6592 - val_loss: 0.6562 - val_acc: 0.6364\n",
      "Epoch 96/150\n",
      "537/537 [==============================] - 0s 540us/step - loss: 0.6411 - acc: 0.6574 - val_loss: 0.6576 - val_acc: 0.6364\n",
      "Epoch 97/150\n",
      "537/537 [==============================] - 0s 483us/step - loss: 0.6438 - acc: 0.6555 - val_loss: 0.6563 - val_acc: 0.6364\n",
      "Epoch 98/150\n",
      "537/537 [==============================] - 0s 504us/step - loss: 0.6418 - acc: 0.6574 - val_loss: 0.6560 - val_acc: 0.6364\n",
      "Epoch 99/150\n",
      "537/537 [==============================] - 0s 511us/step - loss: 0.6464 - acc: 0.6555 - val_loss: 0.6561 - val_acc: 0.6364\n",
      "Epoch 100/150\n",
      "537/537 [==============================] - 0s 474us/step - loss: 0.6414 - acc: 0.6611 - val_loss: 0.6572 - val_acc: 0.6364\n",
      "Epoch 101/150\n",
      "537/537 [==============================] - 0s 508us/step - loss: 0.6410 - acc: 0.6592 - val_loss: 0.6558 - val_acc: 0.6364\n",
      "Epoch 102/150\n",
      "537/537 [==============================] - 0s 514us/step - loss: 0.6435 - acc: 0.6555 - val_loss: 0.6559 - val_acc: 0.6364\n",
      "Epoch 103/150\n",
      "537/537 [==============================] - 0s 467us/step - loss: 0.6411 - acc: 0.6592 - val_loss: 0.6566 - val_acc: 0.6364\n",
      "Epoch 104/150\n",
      "537/537 [==============================] - 0s 516us/step - loss: 0.6393 - acc: 0.6611 - val_loss: 0.6564 - val_acc: 0.6364\n",
      "Epoch 105/150\n",
      "537/537 [==============================] - 0s 502us/step - loss: 0.6412 - acc: 0.6592 - val_loss: 0.6564 - val_acc: 0.6364\n",
      "Epoch 106/150\n",
      "537/537 [==============================] - 0s 482us/step - loss: 0.6437 - acc: 0.6555 - val_loss: 0.6561 - val_acc: 0.6364\n",
      "Epoch 107/150\n",
      "537/537 [==============================] - 0s 461us/step - loss: 0.6411 - acc: 0.6592 - val_loss: 0.6566 - val_acc: 0.6364\n",
      "Epoch 108/150\n",
      "537/537 [==============================] - 0s 283us/step - loss: 0.6410 - acc: 0.6592 - val_loss: 0.6562 - val_acc: 0.6364\n",
      "Epoch 109/150\n",
      "537/537 [==============================] - 0s 278us/step - loss: 0.6410 - acc: 0.6574 - val_loss: 0.6566 - val_acc: 0.6364\n",
      "Epoch 110/150\n",
      "537/537 [==============================] - 0s 277us/step - loss: 0.6397 - acc: 0.6592 - val_loss: 0.6565 - val_acc: 0.6364\n",
      "Epoch 111/150\n",
      "537/537 [==============================] - 0s 299us/step - loss: 0.6412 - acc: 0.6592 - val_loss: 0.6564 - val_acc: 0.6364\n",
      "Epoch 112/150\n",
      "537/537 [==============================] - 0s 286us/step - loss: 0.6419 - acc: 0.6574 - val_loss: 0.6573 - val_acc: 0.6364\n",
      "Epoch 113/150\n",
      "537/537 [==============================] - 0s 285us/step - loss: 0.6397 - acc: 0.6592 - val_loss: 0.6564 - val_acc: 0.6364\n",
      "Epoch 114/150\n",
      "537/537 [==============================] - 0s 300us/step - loss: 0.6426 - acc: 0.6574 - val_loss: 0.6569 - val_acc: 0.6364\n",
      "Epoch 115/150\n",
      "537/537 [==============================] - 0s 274us/step - loss: 0.6411 - acc: 0.6592 - val_loss: 0.6564 - val_acc: 0.6364\n",
      "Epoch 116/150\n",
      "537/537 [==============================] - 0s 299us/step - loss: 0.6412 - acc: 0.6592 - val_loss: 0.6571 - val_acc: 0.6364\n",
      "Epoch 117/150\n",
      "537/537 [==============================] - 0s 282us/step - loss: 0.6401 - acc: 0.6611 - val_loss: 0.6572 - val_acc: 0.6364\n",
      "Epoch 118/150\n",
      "537/537 [==============================] - 0s 297us/step - loss: 0.6407 - acc: 0.6574 - val_loss: 0.6571 - val_acc: 0.6364\n",
      "Epoch 119/150\n",
      "537/537 [==============================] - 0s 277us/step - loss: 0.6405 - acc: 0.6592 - val_loss: 0.6570 - val_acc: 0.6364\n",
      "Epoch 120/150\n",
      "537/537 [==============================] - 0s 283us/step - loss: 0.6417 - acc: 0.6574 - val_loss: 0.6565 - val_acc: 0.6364\n",
      "Epoch 121/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 272us/step - loss: 0.6413 - acc: 0.6592 - val_loss: 0.6563 - val_acc: 0.6364\n",
      "Epoch 122/150\n",
      "537/537 [==============================] - 0s 285us/step - loss: 0.6419 - acc: 0.6592 - val_loss: 0.6564 - val_acc: 0.6364\n",
      "Epoch 123/150\n",
      "537/537 [==============================] - 0s 393us/step - loss: 0.6472 - acc: 0.6536 - val_loss: 0.6568 - val_acc: 0.6364\n",
      "Epoch 124/150\n",
      "537/537 [==============================] - 0s 408us/step - loss: 0.6435 - acc: 0.6574 - val_loss: 0.6565 - val_acc: 0.6364\n",
      "Epoch 125/150\n",
      "537/537 [==============================] - 0s 307us/step - loss: 0.6417 - acc: 0.6592 - val_loss: 0.6561 - val_acc: 0.6364\n",
      "Epoch 126/150\n",
      "537/537 [==============================] - 0s 322us/step - loss: 0.6423 - acc: 0.6574 - val_loss: 0.6566 - val_acc: 0.6364\n",
      "Epoch 127/150\n",
      "537/537 [==============================] - 0s 376us/step - loss: 0.6432 - acc: 0.6592 - val_loss: 0.6569 - val_acc: 0.6364\n",
      "Epoch 128/150\n",
      "537/537 [==============================] - 0s 288us/step - loss: 0.6431 - acc: 0.6574 - val_loss: 0.6562 - val_acc: 0.6364\n",
      "Epoch 129/150\n",
      "537/537 [==============================] - 0s 307us/step - loss: 0.6436 - acc: 0.6574 - val_loss: 0.6570 - val_acc: 0.6364\n",
      "Epoch 130/150\n",
      "537/537 [==============================] - 0s 319us/step - loss: 0.6434 - acc: 0.6574 - val_loss: 0.6563 - val_acc: 0.6364\n",
      "Epoch 131/150\n",
      "537/537 [==============================] - 0s 313us/step - loss: 0.6433 - acc: 0.6592 - val_loss: 0.6558 - val_acc: 0.6364\n",
      "Epoch 132/150\n",
      "537/537 [==============================] - 0s 301us/step - loss: 0.6421 - acc: 0.6611 - val_loss: 0.6561 - val_acc: 0.6364\n",
      "Epoch 133/150\n",
      "537/537 [==============================] - 0s 307us/step - loss: 0.6431 - acc: 0.6574 - val_loss: 0.6564 - val_acc: 0.6364\n",
      "Epoch 134/150\n",
      "537/537 [==============================] - 0s 323us/step - loss: 0.6430 - acc: 0.6611 - val_loss: 0.6566 - val_acc: 0.6364\n",
      "Epoch 135/150\n",
      "537/537 [==============================] - 0s 569us/step - loss: 0.6420 - acc: 0.6592 - val_loss: 0.6558 - val_acc: 0.6364\n",
      "Epoch 136/150\n",
      "537/537 [==============================] - 0s 314us/step - loss: 0.6430 - acc: 0.6592 - val_loss: 0.6560 - val_acc: 0.6364\n",
      "Epoch 137/150\n",
      "537/537 [==============================] - 0s 326us/step - loss: 0.6431 - acc: 0.6592 - val_loss: 0.6560 - val_acc: 0.6364\n",
      "Epoch 138/150\n",
      "537/537 [==============================] - 0s 340us/step - loss: 0.6426 - acc: 0.6592 - val_loss: 0.6575 - val_acc: 0.6364\n",
      "Epoch 139/150\n",
      "537/537 [==============================] - 0s 307us/step - loss: 0.6405 - acc: 0.6611 - val_loss: 0.6562 - val_acc: 0.6364\n",
      "Epoch 140/150\n",
      "537/537 [==============================] - 0s 309us/step - loss: 0.6419 - acc: 0.6592 - val_loss: 0.6563 - val_acc: 0.6364\n",
      "Epoch 141/150\n",
      "537/537 [==============================] - 0s 287us/step - loss: 0.6421 - acc: 0.6611 - val_loss: 0.6562 - val_acc: 0.6364\n",
      "Epoch 142/150\n",
      "537/537 [==============================] - 0s 511us/step - loss: 0.6432 - acc: 0.6574 - val_loss: 0.6562 - val_acc: 0.6364\n",
      "Epoch 143/150\n",
      "537/537 [==============================] - 0s 385us/step - loss: 0.6417 - acc: 0.6574 - val_loss: 0.6566 - val_acc: 0.6364\n",
      "Epoch 144/150\n",
      "537/537 [==============================] - 0s 293us/step - loss: 0.6424 - acc: 0.6592 - val_loss: 0.6570 - val_acc: 0.6364\n",
      "Epoch 145/150\n",
      "537/537 [==============================] - 0s 302us/step - loss: 0.6427 - acc: 0.6592 - val_loss: 0.6570 - val_acc: 0.6364\n",
      "Epoch 146/150\n",
      "537/537 [==============================] - 0s 274us/step - loss: 0.6418 - acc: 0.6592 - val_loss: 0.6565 - val_acc: 0.6364\n",
      "Epoch 147/150\n",
      "537/537 [==============================] - 0s 278us/step - loss: 0.6419 - acc: 0.6611 - val_loss: 0.6570 - val_acc: 0.6364\n",
      "Epoch 148/150\n",
      "537/537 [==============================] - 0s 289us/step - loss: 0.6422 - acc: 0.6592 - val_loss: 0.6562 - val_acc: 0.6364\n",
      "Epoch 149/150\n",
      "537/537 [==============================] - 0s 277us/step - loss: 0.6429 - acc: 0.6574 - val_loss: 0.6572 - val_acc: 0.6364\n",
      "Epoch 150/150\n",
      "537/537 [==============================] - 0s 301us/step - loss: 0.6428 - acc: 0.6574 - val_loss: 0.6570 - val_acc: 0.6364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc1301e4c88>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, validation_data=(X_test,Y_test), nb_epoch=150 , batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 0s 183us/step\n",
      "Test loss: 0.6570200478875792\n",
      "Test accuracy: 0.6363636371377227\n"
     ]
    }
   ],
   "source": [
    "# Desempenho do modelo \n",
    "scores = model.evaluate(X_test, Y_test, verbose = 1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
