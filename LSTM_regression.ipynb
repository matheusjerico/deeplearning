{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de LSTM:\n",
    "- Univariate LSTM Models:\n",
    "\n",
    "Vanilla LSTM\n",
    "\n",
    "Stacked LSTM\n",
    "\n",
    "Bidirectional LSTM\n",
    "\n",
    "CNN LSTM\n",
    "\n",
    "ConvLSTM\n",
    "\n",
    "\n",
    "- Multivariate LSTM Models\n",
    "- Multi-Step LSTM Models\n",
    "- Multivariate Multi-Step LSTM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30] 40\n",
      "[20 30 40] 50\n",
      "[30 40 50] 60\n",
      "[40 50 60] 70\n",
      "[50 60 70] 80\n",
      "[60 70 80] 90\n"
     ]
    }
   ],
   "source": [
    "# split sequencia de univariavel em varios samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # encontrar o fim desse padrão\n",
    "        end_ix = i + n_steps\n",
    "        # check se está além dessa sequência\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # inputs e outputs do padrão\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    " \n",
    "# ddefine sequencia de entrada\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# escolhe o número de time steps\n",
    "n_steps = 3\n",
    "# chama a função\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "# mostra os dados\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição do inputShape e ajustando o X\n",
    "n_steps = 3\n",
    "n_features = 1\n",
    "\n",
    "# [samples, timesteps, features]\n",
    "X = X.reshape(X.shape[0], n_steps, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valina LSTM\n",
    "\n",
    "- Tem apenas uma layers oculta e uma layer de saída\n",
    "\n",
    "#### Definição do Modelo Valina LSTM univariavel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Bidirectional, TimeDistributed, Conv1D, MaxPooling1D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição do modelo\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d4839d5c0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs = 100, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = np.array([70,80,90])\n",
    "x_input = x_input.reshape((1, n_steps,n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102.36032]]\n"
     ]
    }
   ],
   "source": [
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked LSTM\n",
    "\n",
    "- Multiplas layers ocultas e uma layer de saída\n",
    "\n",
    "- Para colocar varias camadas sequenciais, temos que colocar o parâmetro na camada anterior:\n",
    "    return_sequences=True\n",
    "#### Definição do Modelo Stacked LSTM univariavel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d31be9c50>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo previsão\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = np.array([70,80,90])\n",
    "x_input = x_input.reshape(1, n_steps, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102.48096]]\n"
     ]
    }
   ],
   "source": [
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirecional LSTM\n",
    "\n",
    "- aprenda a seqüência de entrada tanto para frente quanto para trás e concatene ambas as interpretações.\n",
    "\n",
    "- a primeira camada oculta em uma camada de wrapper chamada Bidirecional.\n",
    "\n",
    "#### Definição do Modelo Bidirecional LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d2c945eb8>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = np.array([70,80,90])\n",
    "x_input = x_input.reshape(1, n_steps, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102.14232]]\n"
     ]
    }
   ],
   "source": [
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN LSTM\n",
    "\n",
    "- CNN com LSTM\n",
    "#### Definição do Modelo CNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103.00484]]\n"
     ]
    }
   ],
   "source": [
    "# choose a number of time steps\n",
    "n_steps = 4\n",
    "\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "\n",
    "# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
    "n_features = 1\n",
    "n_seq = 2\n",
    "n_steps = 2\n",
    "X = X.reshape((X.shape[0], n_seq, n_steps, n_features))\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_steps, n_features)))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# fit model\n",
    "model.fit(X, y, epochs=500, verbose=0)\n",
    "\n",
    "# demonstrate prediction\n",
    "x_input = np.array([60, 70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_seq, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
      "y: [0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9]\n",
      "7.350883970502764e-05\n",
      "[0.12205631 0.20999527 0.3020866  0.39757013 0.4956392  0.5954754\n",
      " 0.69628197 0.79731363 0.8979009 ]\n"
     ]
    }
   ],
   "source": [
    "# Example of LSTM to learn a sequence\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "# create sequence\n",
    "length = 10\n",
    "sequence = [i/float(length) for i in range(length)]\n",
    "print(sequence)\n",
    "# create X/y pairs\n",
    "df = DataFrame(sequence)\n",
    "df = concat([df.shift(1), df], axis=1)\n",
    "df.dropna(inplace=True)\n",
    "# convert to LSTM friendly format\n",
    "values = df.values\n",
    "X, y = values[:, 0], values[:, 1]\n",
    "X = X.reshape(len(X), 1, 1)\n",
    "print(\"y:\", y)\n",
    "# 1. define network\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(1,1)))\n",
    "model.add(Dense(1))\n",
    "# 2. compile network\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# 3. fit network\n",
    "history = model.fit(X, y, epochs=1000, batch_size=len(X), verbose=0)\n",
    "# 4. evaluate network\n",
    "loss = model.evaluate(X, y, verbose=0)\n",
    "print(loss)\n",
    "# 5. make predictions\n",
    "predictions = model.predict(X, verbose=0)\n",
    "print(predictions[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02205631, -0.00999527, -0.00208659,  0.00242987,  0.0043608 ,\n",
       "        0.00452462,  0.00371803,  0.00268637,  0.00209912])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y - predictions[:,0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
