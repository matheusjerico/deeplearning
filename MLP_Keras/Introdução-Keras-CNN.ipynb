{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução a DeepLearning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Função Softmax:\n",
    "Converter o score em probabilidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hot Enconding:\n",
    "Transformação de uma variável categórica em variável numérica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stochastic Gradient Descent:\n",
    "\n",
    "O treinamento de uma rede neural é convertido em um problema de otimização, com o objetivo de minimizar o erro cometido pela rede.\n",
    "\n",
    "Versão do Gradient Descent em que trabalha com amostras aleatórias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Momentum e Learning Rate\n",
    "\n",
    "Momentum: Incorpora as propriedades da atualização do peso anterior e faz com que os pesos continuem sendo atualizados na mesma direção mesmo que o erro diminui.\n",
    "\n",
    "Learning Rate Decay: Learning rate decay, é usado para diminuir o valor do learning rate conforme os erros diminuem.\n",
    "\n",
    "Learning Rate: 0,01 a 0,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regularização e Droupout\n",
    "\n",
    "Regularização: Método que busca melhorar a capacidade de generalização dos algoritmos de aprendizado por meio de alguma restrição durante a fase de trainamento (ajuda a generalizar o modelo e evitar overfitting).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importando módulos\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando a reprodutividade do código\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega os dados\n",
    "dataset = numpy.loadtxt(\"/home/matheusjerico/Documentos/DSA/05. MachineLearning/Cap-12-IntroduçãoDeepLearning/keras_arquivos/pima-indians-diabetes.csv\", delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa as variáveis 'x' e 'y'\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.DataFrame(X)\n",
    "df_y = pd.DataFrame(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1     2     3    4     5      6     7\n",
       "0  6.0  148.0  72.0  35.0  0.0  33.6  0.627  50.0\n",
       "1  1.0   85.0  66.0  29.0  0.0  26.6  0.351  31.0\n",
       "2  8.0  183.0  64.0   0.0  0.0  23.3  0.672  32.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa os dados entre treino e teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_x, df_y, test_size = 0.3, random_state = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos em Keras são definidos como uma sequência de camadas. Isto facilita a criação do modelo, bastando inserir uma camada por vez até que estejamos satisfeitos com a topologia da rede.\n",
    "\n",
    "A primeira coisa a se fazer é garantir que a camada de entrada tem o número correto de inputs. Isto pode ser especificado enquanto criando a primeira camada com o argumento ‘input_dim’, atribuindo-lhe 8, para o variáveis de entrada. No exemplo a estrutura de rede é fully-connected com 3 camadas. Isto é, todos os neurônios se comunicam antes da saída.\n",
    "\n",
    "Nós podemos especificar o número de neurônios na camada como primeiro argumento, o método de inicialização como segundo argmento sendo ‘init’ e especificar a função de ativação utilizando o argumento ‘activation’.\n",
    "\n",
    "Neste caso, nós inicializamos o peso da rede para um pequeno número randômico gerado a partir de uma distribuição uniforme (‘uniform’), entre 0 e 0.05, nesse caso, porque esse é o peso padrão da distribuição uniforme no Keras. Uma alternativa tradicional seria o ‘normal’, gerando assim pequenos números randômicos a partir de uma distribuição gaussiana. Também será usada a função de ativação ‘relu’ nas primeiras duas camadas e a função sigmoide na camada de saída. O resultado deverá ser algo entre 0 e 1 com um threshold padrão de 0.5.\n",
    "\n",
    "Construindo o código, você pode notar que a primeira camada tem 12 neurônios e espera 8 variáveis de entrada. A segunda camada possui 8 neurônios e finalmente a saída tem 1 neurônio fazendo a predição da classe alvo (tendência a desenvolver diabetes ou não)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o modelo\n",
    "model= Sequential()\n",
    "model.add(Dense(15, input_dim = 8, kernel_initializer = 'normal', activation= 'relu'))\n",
    "model.add(Dense(12, kernel_initializer = 'normal', activation = 'relu'))\n",
    "model.add(Dense(8, kernel_initializer = 'normal', activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, kernel_initializer = 'normal', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A compilação do modelo usa uma eficiente biblioteca numérica de backend, como Theano or TensorFlow. O backend automaticamente escolhe o melhor caminho para representar a rede e fazer predições.\n",
    "\n",
    "Será necessário em algum momento especificar a função de perda para avaliar os pesos. Nesse exemplo foi definido o uso da função de perda logarítmica, definido em Keras como “binary_crossentropy”. Também é utilizado o algoritmo Stochastic Gradient Descent para otimização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilando o modelo\n",
    "model.compile(loss= 'binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheusjerico/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.6635 - acc: 0.6458\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 324us/step - loss: 0.6442 - acc: 0.6563\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 357us/step - loss: 0.6422 - acc: 0.6536\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 299us/step - loss: 0.6413 - acc: 0.6680\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 307us/step - loss: 0.6442 - acc: 0.6510\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 374us/step - loss: 0.6462 - acc: 0.6510\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 453us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 295us/step - loss: 0.6481 - acc: 0.6510\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 289us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 267us/step - loss: 0.6473 - acc: 0.6510\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.6473 - acc: 0.6510\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.6472 - acc: 0.6510\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 282us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 270us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 276us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 272us/step - loss: 0.6479 - acc: 0.6510\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 267us/step - loss: 0.6447 - acc: 0.6510\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 283us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 286us/step - loss: 0.6454 - acc: 0.6510\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 260us/step - loss: 0.6462 - acc: 0.6510\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 283us/step - loss: 0.6479 - acc: 0.6510\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 308us/step - loss: 0.6443 - acc: 0.6510\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 307us/step - loss: 0.6436 - acc: 0.6510\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 331us/step - loss: 0.6457 - acc: 0.6510\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 360us/step - loss: 0.6457 - acc: 0.6510\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 347us/step - loss: 0.6411 - acc: 0.6510\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 367us/step - loss: 0.6417 - acc: 0.6510\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 338us/step - loss: 0.6313 - acc: 0.6510\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 430us/step - loss: 0.6411 - acc: 0.6510\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 384us/step - loss: 0.6362 - acc: 0.6510\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 365us/step - loss: 0.6486 - acc: 0.6510\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 535us/step - loss: 0.6478 - acc: 0.6510\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 486us/step - loss: 0.6473 - acc: 0.6510\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 383us/step - loss: 0.6473 - acc: 0.6510\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s 370us/step - loss: 0.6482 - acc: 0.6510\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 352us/step - loss: 0.6477 - acc: 0.6510\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 342us/step - loss: 0.6472 - acc: 0.6510\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 383us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 357us/step - loss: 0.6473 - acc: 0.6510\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 349us/step - loss: 0.6477 - acc: 0.6510\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 338us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 336us/step - loss: 0.6480 - acc: 0.6510\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 333us/step - loss: 0.6472 - acc: 0.6510\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 337us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 341us/step - loss: 0.6480 - acc: 0.6510\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 375us/step - loss: 0.6472 - acc: 0.6510\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 335us/step - loss: 0.6472 - acc: 0.6510\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 372us/step - loss: 0.6470 - acc: 0.6510\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 368us/step - loss: 0.6451 - acc: 0.6510\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 380us/step - loss: 0.6417 - acc: 0.6510\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 333us/step - loss: 0.6426 - acc: 0.6510\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 374us/step - loss: 0.6417 - acc: 0.6510\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 352us/step - loss: 0.6439 - acc: 0.6510\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 430us/step - loss: 0.6429 - acc: 0.6510\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 355us/step - loss: 0.6409 - acc: 0.6510\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 366us/step - loss: 0.6485 - acc: 0.6510\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 380us/step - loss: 0.6472 - acc: 0.6510\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 334us/step - loss: 0.6449 - acc: 0.6510\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 381us/step - loss: 0.6412 - acc: 0.6510\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 327us/step - loss: 0.6440 - acc: 0.6510\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 371us/step - loss: 0.6396 - acc: 0.6510\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 316us/step - loss: 0.6423 - acc: 0.6510\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 339us/step - loss: 0.6481 - acc: 0.6510\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 331us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 380us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 336us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 397us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 371us/step - loss: 0.6480 - acc: 0.6510\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 368us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 381us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 345us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 329us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 371us/step - loss: 0.6479 - acc: 0.6510\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 339us/step - loss: 0.6478 - acc: 0.6510\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 429us/step - loss: 0.6478 - acc: 0.6510\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 394us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 362us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 391us/step - loss: 0.6473 - acc: 0.6510\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 352us/step - loss: 0.6480 - acc: 0.6510\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 359us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 364us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 345us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s 352us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 325us/step - loss: 0.6471 - acc: 0.6510\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 339us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 329us/step - loss: 0.6479 - acc: 0.6510\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 365us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 313us/step - loss: 0.6479 - acc: 0.6510\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 468us/step - loss: 0.6484 - acc: 0.6510\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 572us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 330us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 357us/step - loss: 0.6485 - acc: 0.6510\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 340us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 357us/step - loss: 0.6477 - acc: 0.6510\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 340us/step - loss: 0.6481 - acc: 0.6510\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 376us/step - loss: 0.6481 - acc: 0.6510\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 364us/step - loss: 0.6471 - acc: 0.6510\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 506us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 394us/step - loss: 0.6477 - acc: 0.6510\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 479us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 328us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 353us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 342us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 398us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 356us/step - loss: 0.6473 - acc: 0.6510\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 538us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 508us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 484us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 380us/step - loss: 0.6484 - acc: 0.6510\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 510us/step - loss: 0.6485 - acc: 0.6510\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 367us/step - loss: 0.6478 - acc: 0.6510\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 418us/step - loss: 0.6482 - acc: 0.6510\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 512us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 384us/step - loss: 0.6482 - acc: 0.6510\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 335us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 378us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 392us/step - loss: 0.6477 - acc: 0.6510\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 395us/step - loss: 0.6472 - acc: 0.6510\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 400us/step - loss: 0.6471 - acc: 0.6510\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 441us/step - loss: 0.6489 - acc: 0.6510\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 381us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 345us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 389us/step - loss: 0.6483 - acc: 0.6510\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 379us/step - loss: 0.6473 - acc: 0.6510\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 366us/step - loss: 0.6484 - acc: 0.6510\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 434us/step - loss: 0.6479 - acc: 0.6510\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 342us/step - loss: 0.6478 - acc: 0.6510\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 399us/step - loss: 0.6479 - acc: 0.6510\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 367us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 347us/step - loss: 0.6473 - acc: 0.6510\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 340us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 286us/step - loss: 0.6473 - acc: 0.6510\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 348us/step - loss: 0.6477 - acc: 0.6510\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 313us/step - loss: 0.6488 - acc: 0.6510\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.6478 - acc: 0.6510\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 279us/step - loss: 0.6472 - acc: 0.6510\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 286us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 297us/step - loss: 0.6473 - acc: 0.6510\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 286us/step - loss: 0.6482 - acc: 0.6510\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 289us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 298us/step - loss: 0.6478 - acc: 0.6510\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 321us/step - loss: 0.6480 - acc: 0.6510\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.6473 - acc: 0.6510\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 306us/step - loss: 0.6475 - acc: 0.6510\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.6476 - acc: 0.6510\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 373us/step - loss: 0.6474 - acc: 0.6510\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 308us/step - loss: 0.6477 - acc: 0.6510\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 365us/step - loss: 0.6475 - acc: 0.6510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8277d80e80>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executa o modelo e valida nos mesmo dados em que foi criado (Treino)\n",
    "model.fit(X, Y, nb_epoch=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compila o modelo com outro otimizador\n",
    "model.compile(loss= \"binary_crossentropy\",\n",
    "              optimizer= \"adam\",\n",
    "              metrics= [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheusjerico/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 388us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 395us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 394us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 379us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 394us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 391us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 369us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 380us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 403us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 423us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 428us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 397us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 423us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 373us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 415us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 424us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 394us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 416us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 404us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 386us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 404us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 420us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 409us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 393us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 524us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 541us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 526us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 559us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 522us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 390us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 408us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 549us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 509us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 566us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s 626us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 403us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 421us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 405us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 450us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 398us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 402us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 413us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 420us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 468us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 417us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 393us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 438us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 437us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 436us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 398us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 458us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 414us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 394us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 400us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 503us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 445us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 436us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 433us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 453us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 400us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 407us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 398us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 453us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 438us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 427us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 446us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 429us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 391us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 424us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 442us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 396us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 408us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 413us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 453us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 449us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 442us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 412us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 442us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 429us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 423us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 440us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 359us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s 368us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 358us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 497us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 350us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 386us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 346us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 372us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 328us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 339us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 464us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 617us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 384us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 336us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 365us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 342us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 365us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 406us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 354us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 396us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 483us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 527us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 579us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 388us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 392us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 408us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 396us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 423us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 421us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 384us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 395us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 374us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 387us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 372us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 396us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 403us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 414us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 440us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 413us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 368us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 454us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 411us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 407us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 402us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 415us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 384us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 444us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 396us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 407us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 431us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 430us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 456us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 440us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 401us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 584us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 538us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 385us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 382us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 552us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 509us/step - loss: 0.6468 - acc: 0.6510\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 460us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 399us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 387us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 499us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 406us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 438us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 427us/step - loss: 0.6469 - acc: 0.6510\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 400us/step - loss: 0.6469 - acc: 0.6510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8277d80f98>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, nb_epoch=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 4.23786379e-02,  1.03107337e-02,  4.14780602e-02,\n",
       "         -1.38774782e-01, -2.38398444e-02,  3.88940200e-02,\n",
       "          2.63786502e-02, -1.36928841e-01,  1.94949005e-03,\n",
       "         -4.54510935e-03,  7.65041308e-03,  7.36444211e-03,\n",
       "          3.66879441e-02,  4.53175604e-02, -2.68868923e-01],\n",
       "        [ 3.18145123e-03, -1.02515277e-02, -1.46981388e-01,\n",
       "         -8.66659820e-01, -4.44386378e-02, -3.17812152e-03,\n",
       "         -1.49915125e-02, -5.46163321e-01, -1.05619147e-01,\n",
       "          1.40603737e-03, -1.70026705e-01, -4.02723290e-02,\n",
       "         -4.45738696e-02, -1.71091128e-02, -9.53844428e-01],\n",
       "        [-5.37904277e-02, -4.48761843e-02,  4.70653586e-02,\n",
       "          7.26093888e-01, -2.55120527e-02, -5.54609112e-02,\n",
       "         -4.14041430e-02,  7.81326056e-01,  5.91372140e-02,\n",
       "         -2.17949420e-01,  6.26129359e-02, -5.01411080e-01,\n",
       "         -5.55047803e-02, -5.20583540e-02,  5.53717375e-01],\n",
       "        [-4.65553328e-02, -2.01979280e-02,  7.56341517e-02,\n",
       "          9.17582288e-02,  3.62171791e-02, -1.46050053e-03,\n",
       "          3.27197947e-02,  9.49662831e-03,  4.15111855e-02,\n",
       "         -7.88447782e-02,  5.03982641e-02, -1.34323269e-01,\n",
       "         -2.72904616e-02,  4.46496978e-02,  1.63789958e-01],\n",
       "        [-6.94845151e-03,  1.44474418e-03, -7.35792667e-02,\n",
       "         -4.11968172e-01, -4.34851162e-02, -1.60603840e-02,\n",
       "         -2.32937280e-02, -1.35869488e-01, -4.84107472e-02,\n",
       "         -1.54912576e-01, -7.54150897e-02, -1.81021929e-01,\n",
       "          1.29708331e-02, -3.00950633e-04, -4.08504575e-01],\n",
       "        [-5.69157414e-02, -3.17249894e-02,  2.65501589e-02,\n",
       "         -6.06351085e-02, -1.77672878e-02,  2.05412060e-02,\n",
       "          2.31387280e-02,  5.99870831e-02, -2.93584038e-02,\n",
       "         -3.25712301e-02,  2.86716353e-02, -7.46345371e-02,\n",
       "          1.85189545e-02, -3.30588408e-02, -2.07957119e-01],\n",
       "        [-1.31407287e-02, -3.44433822e-02, -7.92881008e-03,\n",
       "         -4.17936891e-02, -1.27897151e-02, -2.71743294e-02,\n",
       "         -3.30882682e-03, -2.91147977e-02, -4.37323675e-02,\n",
       "         -4.05280069e-02, -8.94394703e-03, -3.86040360e-02,\n",
       "         -4.07055654e-02, -2.35607438e-02,  1.29404273e-02],\n",
       "        [-4.61413115e-02, -4.13003117e-02,  4.17183414e-02,\n",
       "         -2.02739850e-01,  3.20818275e-03, -3.49370353e-02,\n",
       "         -2.18117964e-02, -9.54528302e-02,  3.05268131e-02,\n",
       "         -8.23811740e-02,  6.48621172e-02, -1.44160375e-01,\n",
       "         -2.80615557e-02,  2.95295157e-02, -3.59622985e-01]], dtype=float32),\n",
       " array([ 4.47141902e-05, -3.31788106e-05, -1.28037154e-05,  2.40315944e-02,\n",
       "         0.00000000e+00, -2.79361324e-04, -1.23641788e-04,  2.11482942e-02,\n",
       "         3.59349971e-04, -4.62537259e-03,  1.35440903e-03, -9.66441445e-03,\n",
       "        -1.13669106e-04, -6.62924576e-05,  2.22976301e-02], dtype=float32),\n",
       " array([[ 9.40354820e-03, -1.53080709e-02,  3.08300965e-02,\n",
       "          1.43246632e-02,  4.32699472e-02,  3.21489898e-03,\n",
       "          3.88995148e-02,  2.86489036e-02,  2.59966981e-02,\n",
       "          3.38483341e-02, -1.60553791e-02,  1.30780507e-02],\n",
       "        [ 2.61570718e-02, -1.13716014e-02, -4.41108719e-02,\n",
       "          3.75822447e-02, -1.54537074e-02,  2.94244327e-02,\n",
       "          1.20518692e-02, -1.97914708e-02, -4.68610711e-02,\n",
       "         -2.35378742e-02,  3.83385234e-02, -4.01234478e-02],\n",
       "        [-8.44185427e-02, -8.35900158e-02,  1.00785214e-02,\n",
       "         -7.24343210e-02, -4.75333072e-02, -6.33120537e-02,\n",
       "         -3.96519713e-02, -7.87357092e-02, -8.33508819e-02,\n",
       "         -4.60649356e-02, -6.38757721e-02, -1.44616980e-02],\n",
       "        [-7.54247978e-02, -2.73709476e-01, -3.16811465e-02,\n",
       "          1.89920124e-02, -4.39713635e-02,  5.96694463e-06,\n",
       "         -8.50791577e-03, -7.33447522e-02, -6.36961609e-02,\n",
       "         -1.33951940e-02, -5.95621904e-03, -3.66113055e-03],\n",
       "        [ 4.76468243e-02,  4.84244712e-02,  3.93658392e-02,\n",
       "         -1.04085431e-02, -2.39120964e-02, -3.98158431e-02,\n",
       "         -3.02862376e-04,  3.36424820e-02, -1.18956938e-02,\n",
       "          1.29292123e-02,  3.38453911e-02, -2.33123060e-02],\n",
       "        [ 2.08600350e-02, -1.46636739e-02,  3.84519137e-02,\n",
       "         -4.92092520e-02, -2.56470330e-02,  3.40487510e-02,\n",
       "         -4.96180803e-02, -3.55512500e-02,  3.05930842e-02,\n",
       "          1.96835194e-02,  3.24192718e-02,  2.31581600e-03],\n",
       "        [ 4.06842008e-02, -1.25343315e-02,  4.56196368e-02,\n",
       "         -8.53457209e-03, -2.78985500e-03,  1.31245144e-02,\n",
       "          1.15972254e-02, -3.13949585e-03, -2.96507981e-02,\n",
       "         -2.11217925e-02, -3.56826633e-02, -2.89912093e-02],\n",
       "        [-9.92540494e-02, -2.38885954e-01, -3.88123207e-02,\n",
       "         -3.59058261e-01, -5.90613782e-02, -4.44685332e-02,\n",
       "         -4.24103253e-02, -2.67035831e-02, -3.43871206e-01,\n",
       "         -3.37297730e-02, -3.47500783e-03, -2.50431653e-02],\n",
       "        [ 1.38960565e-02, -6.63671568e-02, -2.70750001e-02,\n",
       "         -4.08270136e-02, -4.61819880e-02, -6.15572780e-02,\n",
       "          2.86571030e-03, -1.42121753e-02, -7.92800561e-02,\n",
       "          2.03789957e-02,  1.96244176e-02,  1.35562653e-02],\n",
       "        [-3.01004555e-02, -5.96892573e-02, -2.86132153e-02,\n",
       "         -2.19837297e-02,  1.00615501e-01,  1.81721337e-02,\n",
       "         -3.66623886e-02, -3.72811481e-02, -4.44017276e-02,\n",
       "          1.09012172e-01,  5.73738478e-02,  2.01188046e-02],\n",
       "        [-7.89759308e-02, -1.03454947e-01,  6.36490178e-04,\n",
       "         -7.09828734e-02, -8.09822115e-04, -2.35968549e-02,\n",
       "          2.16125585e-02, -4.56224568e-02, -1.91107839e-02,\n",
       "         -3.18815224e-02, -2.20882427e-02, -4.08223309e-02],\n",
       "        [-7.49370679e-02, -8.98887068e-02, -2.69796345e-02,\n",
       "         -3.08415014e-02, -6.67044371e-02, -2.56286394e-02,\n",
       "         -6.73078746e-03, -8.88130814e-02, -7.82670453e-03,\n",
       "          1.08661421e-01,  5.51876947e-02, -1.87118113e-01],\n",
       "        [-2.87392382e-02, -2.43734121e-02,  2.74162311e-02,\n",
       "          4.92699025e-03,  4.91733775e-02, -2.35112235e-02,\n",
       "         -2.82815229e-02, -1.83094162e-02, -3.53972055e-02,\n",
       "         -3.09046227e-02, -5.55517478e-03,  4.63824831e-02],\n",
       "        [ 1.50306546e-03,  4.46351469e-02,  3.62752751e-02,\n",
       "          8.96080397e-03,  4.58511040e-02, -3.00273430e-02,\n",
       "          1.92948896e-02, -4.66677547e-02, -2.32669730e-02,\n",
       "          3.28896306e-02, -4.96120006e-02,  2.60469243e-02],\n",
       "        [-7.67333582e-02, -1.75957426e-01, -1.59603916e-02,\n",
       "         -1.04654424e-01,  1.71929001e-04, -2.00159680e-02,\n",
       "         -9.60158557e-03, -4.55720611e-02, -1.96531713e-02,\n",
       "         -2.58042440e-02, -1.10973939e-02, -3.27907689e-02]], dtype=float32),\n",
       " array([-5.6265164e-03, -1.3554166e-02, -7.7133802e-05, -2.3720808e-02,\n",
       "        -2.1043412e-02, -9.5494688e-03, -1.8168807e-03, -5.2771573e-03,\n",
       "        -2.3478469e-02, -6.9534048e-02, -2.9366681e-02, -2.1721505e-02],\n",
       "       dtype=float32),\n",
       " array([[-0.0089373 ],\n",
       "        [ 0.04372154],\n",
       "        [-0.00592972],\n",
       "        [-0.15207058],\n",
       "        [ 0.04168577],\n",
       "        [ 0.01913253],\n",
       "        [-0.02995265],\n",
       "        [-0.01395848],\n",
       "        [ 0.02150236],\n",
       "        [ 0.10795524],\n",
       "        [ 0.09632976],\n",
       "        [-0.12524329]], dtype=float32),\n",
       " array([-0.6245494], dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 15)                135       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12)                192       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 340\n",
      "Trainable params: 340\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 380us/step\n",
      "acc: 65.10%\n"
     ]
    }
   ],
   "source": [
    "# Avaliar o resultado do modelo\n",
    "scores = model.evaluate(X,Y)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 514 samples, validate on 254 samples\n",
      "Epoch 1/150\n",
      "390/514 [=====================>........] - ETA: 0s - loss: 0.6531 - acc: 0.6410"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheusjerico/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 486us/step - loss: 0.6536 - acc: 0.6401 - val_loss: 0.6331 - val_acc: 0.6732\n",
      "Epoch 2/150\n",
      "514/514 [==============================] - 0s 429us/step - loss: 0.6536 - acc: 0.6401 - val_loss: 0.6332 - val_acc: 0.6732\n",
      "Epoch 3/150\n",
      "514/514 [==============================] - 0s 443us/step - loss: 0.6537 - acc: 0.6401 - val_loss: 0.6333 - val_acc: 0.6732\n",
      "Epoch 4/150\n",
      "514/514 [==============================] - 0s 477us/step - loss: 0.6536 - acc: 0.6401 - val_loss: 0.6333 - val_acc: 0.6732\n",
      "Epoch 5/150\n",
      "514/514 [==============================] - 0s 556us/step - loss: 0.6536 - acc: 0.6401 - val_loss: 0.6334 - val_acc: 0.6732\n",
      "Epoch 6/150\n",
      "514/514 [==============================] - 0s 445us/step - loss: 0.6537 - acc: 0.6401 - val_loss: 0.6333 - val_acc: 0.6732\n",
      "Epoch 7/150\n",
      "514/514 [==============================] - 0s 480us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6335 - val_acc: 0.6732\n",
      "Epoch 8/150\n",
      "514/514 [==============================] - 0s 478us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6336 - val_acc: 0.6732\n",
      "Epoch 9/150\n",
      "514/514 [==============================] - 0s 807us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6335 - val_acc: 0.6732\n",
      "Epoch 10/150\n",
      "514/514 [==============================] - 0s 656us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6335 - val_acc: 0.6732\n",
      "Epoch 11/150\n",
      "514/514 [==============================] - 0s 614us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6336 - val_acc: 0.6732\n",
      "Epoch 12/150\n",
      "514/514 [==============================] - 0s 435us/step - loss: 0.6536 - acc: 0.6401 - val_loss: 0.6337 - val_acc: 0.6732\n",
      "Epoch 13/150\n",
      "514/514 [==============================] - 0s 422us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6338 - val_acc: 0.6732\n",
      "Epoch 14/150\n",
      "514/514 [==============================] - 0s 424us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6337 - val_acc: 0.6732\n",
      "Epoch 15/150\n",
      "514/514 [==============================] - 0s 540us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6338 - val_acc: 0.6732\n",
      "Epoch 16/150\n",
      "514/514 [==============================] - 0s 541us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6338 - val_acc: 0.6732\n",
      "Epoch 17/150\n",
      "514/514 [==============================] - 0s 554us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6337 - val_acc: 0.6732\n",
      "Epoch 18/150\n",
      "514/514 [==============================] - 0s 634us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.6732\n",
      "Epoch 19/150\n",
      "514/514 [==============================] - 0s 491us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.6732\n",
      "Epoch 20/150\n",
      "514/514 [==============================] - 0s 518us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.6732\n",
      "Epoch 21/150\n",
      "514/514 [==============================] - 0s 510us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.6732\n",
      "Epoch 22/150\n",
      "514/514 [==============================] - 0s 592us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 23/150\n",
      "514/514 [==============================] - 0s 623us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 24/150\n",
      "514/514 [==============================] - 0s 524us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 25/150\n",
      "514/514 [==============================] - 0s 452us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 26/150\n",
      "514/514 [==============================] - 0s 510us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 27/150\n",
      "514/514 [==============================] - 0s 514us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 28/150\n",
      "514/514 [==============================] - 0s 498us/step - loss: 0.6536 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 29/150\n",
      "514/514 [==============================] - 0s 510us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 30/150\n",
      "514/514 [==============================] - 0s 437us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 31/150\n",
      "514/514 [==============================] - 0s 667us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 32/150\n",
      "514/514 [==============================] - 0s 506us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 33/150\n",
      "514/514 [==============================] - 0s 508us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 34/150\n",
      "514/514 [==============================] - 0s 520us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 35/150\n",
      "514/514 [==============================] - 0s 403us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 36/150\n",
      "514/514 [==============================] - 0s 413us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 37/150\n",
      "514/514 [==============================] - 0s 649us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 38/150\n",
      "514/514 [==============================] - 0s 535us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 39/150\n",
      "514/514 [==============================] - 0s 523us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 40/150\n",
      "514/514 [==============================] - 0s 543us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 41/150\n",
      "514/514 [==============================] - 0s 555us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 42/150\n",
      "514/514 [==============================] - 0s 623us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 43/150\n",
      "514/514 [==============================] - 0s 560us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 44/150\n",
      "514/514 [==============================] - 0s 645us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 45/150\n",
      "514/514 [==============================] - 0s 717us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 46/150\n",
      "514/514 [==============================] - 0s 565us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 47/150\n",
      "514/514 [==============================] - 0s 526us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 48/150\n",
      "514/514 [==============================] - 0s 590us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6345 - val_acc: 0.6732\n",
      "Epoch 49/150\n",
      "514/514 [==============================] - 0s 505us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6345 - val_acc: 0.6732\n",
      "Epoch 50/150\n",
      "514/514 [==============================] - 0s 499us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 51/150\n",
      "514/514 [==============================] - 0s 518us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 52/150\n",
      "514/514 [==============================] - 0s 565us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 53/150\n",
      "514/514 [==============================] - 0s 525us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 54/150\n",
      "514/514 [==============================] - 0s 506us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 55/150\n",
      "514/514 [==============================] - 0s 543us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 56/150\n",
      "514/514 [==============================] - 0s 525us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 57/150\n",
      "514/514 [==============================] - 0s 717us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 58/150\n",
      "514/514 [==============================] - 0s 493us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 59/150\n",
      "514/514 [==============================] - 0s 529us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 60/150\n",
      "514/514 [==============================] - 0s 529us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 61/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 425us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 62/150\n",
      "514/514 [==============================] - 0s 401us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 63/150\n",
      "514/514 [==============================] - 0s 401us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 64/150\n",
      "514/514 [==============================] - 0s 414us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 65/150\n",
      "514/514 [==============================] - 0s 406us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 66/150\n",
      "514/514 [==============================] - 0s 394us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 67/150\n",
      "514/514 [==============================] - 0s 418us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 68/150\n",
      "514/514 [==============================] - 0s 406us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 69/150\n",
      "514/514 [==============================] - 0s 488us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 70/150\n",
      "514/514 [==============================] - 0s 536us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 71/150\n",
      "514/514 [==============================] - 0s 551us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 72/150\n",
      "514/514 [==============================] - 0s 554us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 73/150\n",
      "514/514 [==============================] - 0s 607us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 74/150\n",
      "514/514 [==============================] - 0s 475us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 75/150\n",
      "514/514 [==============================] - 0s 527us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 76/150\n",
      "514/514 [==============================] - 0s 652us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 77/150\n",
      "514/514 [==============================] - 0s 522us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6345 - val_acc: 0.6732\n",
      "Epoch 78/150\n",
      "514/514 [==============================] - 0s 540us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 79/150\n",
      "514/514 [==============================] - 0s 505us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 80/150\n",
      "514/514 [==============================] - 0s 489us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 81/150\n",
      "514/514 [==============================] - 0s 715us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 82/150\n",
      "514/514 [==============================] - 0s 464us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 83/150\n",
      "514/514 [==============================] - 0s 488us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 84/150\n",
      "514/514 [==============================] - 0s 447us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 85/150\n",
      "514/514 [==============================] - ETA: 0s - loss: 0.6440 - acc: 0.656 - 0s 386us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 86/150\n",
      "514/514 [==============================] - 0s 497us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 87/150\n",
      "514/514 [==============================] - 0s 411us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 88/150\n",
      "514/514 [==============================] - 0s 415us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 89/150\n",
      "514/514 [==============================] - 0s 415us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 90/150\n",
      "514/514 [==============================] - 0s 492us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 91/150\n",
      "514/514 [==============================] - 0s 532us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 92/150\n",
      "514/514 [==============================] - 0s 836us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 93/150\n",
      "514/514 [==============================] - 0s 535us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 94/150\n",
      "514/514 [==============================] - 0s 545us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 95/150\n",
      "514/514 [==============================] - 0s 455us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 96/150\n",
      "514/514 [==============================] - 0s 722us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 97/150\n",
      "514/514 [==============================] - 0s 558us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 98/150\n",
      "514/514 [==============================] - 0s 605us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 99/150\n",
      "514/514 [==============================] - 0s 556us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 100/150\n",
      "514/514 [==============================] - 0s 449us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 101/150\n",
      "514/514 [==============================] - 0s 438us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 102/150\n",
      "514/514 [==============================] - 0s 447us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 103/150\n",
      "514/514 [==============================] - 0s 436us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 104/150\n",
      "514/514 [==============================] - 0s 648us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 105/150\n",
      "514/514 [==============================] - 0s 708us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 106/150\n",
      "514/514 [==============================] - 0s 769us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 107/150\n",
      "514/514 [==============================] - 0s 575us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 108/150\n",
      "514/514 [==============================] - 0s 575us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 109/150\n",
      "514/514 [==============================] - 0s 588us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 110/150\n",
      "514/514 [==============================] - 0s 520us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 111/150\n",
      "514/514 [==============================] - 0s 568us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 112/150\n",
      "514/514 [==============================] - 0s 555us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 113/150\n",
      "514/514 [==============================] - 0s 557us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 114/150\n",
      "514/514 [==============================] - 0s 640us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 115/150\n",
      "514/514 [==============================] - 0s 508us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 116/150\n",
      "514/514 [==============================] - 0s 517us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 117/150\n",
      "514/514 [==============================] - 0s 707us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 118/150\n",
      "514/514 [==============================] - 0s 578us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6345 - val_acc: 0.6732\n",
      "Epoch 119/150\n",
      "514/514 [==============================] - 0s 573us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 120/150\n",
      "514/514 [==============================] - 0s 540us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/150\n",
      "514/514 [==============================] - 0s 443us/step - loss: 0.6536 - acc: 0.6401 - val_loss: 0.6345 - val_acc: 0.6732\n",
      "Epoch 122/150\n",
      "514/514 [==============================] - 0s 480us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 123/150\n",
      "514/514 [==============================] - 0s 507us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 124/150\n",
      "514/514 [==============================] - 0s 514us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 125/150\n",
      "514/514 [==============================] - 0s 507us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6345 - val_acc: 0.6732\n",
      "Epoch 126/150\n",
      "514/514 [==============================] - 0s 550us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 127/150\n",
      "514/514 [==============================] - 0s 506us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 128/150\n",
      "514/514 [==============================] - 0s 476us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 129/150\n",
      "514/514 [==============================] - 0s 562us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 130/150\n",
      "514/514 [==============================] - 0s 538us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 131/150\n",
      "514/514 [==============================] - 0s 543us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 132/150\n",
      "514/514 [==============================] - 0s 523us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 133/150\n",
      "514/514 [==============================] - 0s 523us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 134/150\n",
      "514/514 [==============================] - 0s 566us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 135/150\n",
      "514/514 [==============================] - 0s 513us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 136/150\n",
      "514/514 [==============================] - 0s 619us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 137/150\n",
      "514/514 [==============================] - 0s 549us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 138/150\n",
      "514/514 [==============================] - 0s 588us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 139/150\n",
      "514/514 [==============================] - 0s 507us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6345 - val_acc: 0.6732\n",
      "Epoch 140/150\n",
      "514/514 [==============================] - 0s 771us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 141/150\n",
      "514/514 [==============================] - 0s 544us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6345 - val_acc: 0.6732\n",
      "Epoch 142/150\n",
      "514/514 [==============================] - 0s 407us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 143/150\n",
      "514/514 [==============================] - 0s 401us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 144/150\n",
      "514/514 [==============================] - 0s 410us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 145/150\n",
      "514/514 [==============================] - 0s 420us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 146/150\n",
      "514/514 [==============================] - 0s 416us/step - loss: 0.6535 - acc: 0.6401 - val_loss: 0.6345 - val_acc: 0.6732\n",
      "Epoch 147/150\n",
      "514/514 [==============================] - 0s 735us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6345 - val_acc: 0.6732\n",
      "Epoch 148/150\n",
      "514/514 [==============================] - 0s 717us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6346 - val_acc: 0.6732\n",
      "Epoch 149/150\n",
      "514/514 [==============================] - 0s 535us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6346 - val_acc: 0.6732\n",
      "Epoch 150/150\n",
      "514/514 [==============================] - 0s 511us/step - loss: 0.6534 - acc: 0.6401 - val_loss: 0.6345 - val_acc: 0.6732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f82441e8320>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executa o modelo e faz validação em um conjunto de dados separados automaticamente para testes\n",
    "model.fit(X,Y, validation_split=0.33, nb_epoch=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheusjerico/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 537 samples, validate on 231 samples\n",
      "Epoch 1/150\n",
      "537/537 [==============================] - 2s 3ms/step - loss: 0.6901 - acc: 0.6220 - val_loss: 0.6871 - val_acc: 0.6364\n",
      "Epoch 2/150\n",
      "537/537 [==============================] - 0s 590us/step - loss: 0.6819 - acc: 0.6574 - val_loss: 0.6782 - val_acc: 0.6364\n",
      "Epoch 3/150\n",
      "537/537 [==============================] - 0s 778us/step - loss: 0.6600 - acc: 0.6574 - val_loss: 0.6588 - val_acc: 0.6364\n",
      "Epoch 4/150\n",
      "537/537 [==============================] - 0s 504us/step - loss: 0.6645 - acc: 0.6518 - val_loss: 0.6500 - val_acc: 0.6364\n",
      "Epoch 5/150\n",
      "537/537 [==============================] - 0s 511us/step - loss: 0.6418 - acc: 0.6685 - val_loss: 0.6311 - val_acc: 0.6450\n",
      "Epoch 6/150\n",
      "537/537 [==============================] - 0s 563us/step - loss: 0.6323 - acc: 0.6760 - val_loss: 0.6217 - val_acc: 0.6623\n",
      "Epoch 7/150\n",
      "537/537 [==============================] - 0s 593us/step - loss: 0.6293 - acc: 0.6760 - val_loss: 0.6260 - val_acc: 0.6883\n",
      "Epoch 8/150\n",
      "537/537 [==============================] - 0s 565us/step - loss: 0.6252 - acc: 0.6704 - val_loss: 0.6141 - val_acc: 0.6926\n",
      "Epoch 9/150\n",
      "537/537 [==============================] - 0s 577us/step - loss: 0.6169 - acc: 0.7058 - val_loss: 0.6028 - val_acc: 0.6970\n",
      "Epoch 10/150\n",
      "537/537 [==============================] - 0s 806us/step - loss: 0.6129 - acc: 0.7076 - val_loss: 0.5998 - val_acc: 0.6926\n",
      "Epoch 11/150\n",
      "537/537 [==============================] - 0s 567us/step - loss: 0.6136 - acc: 0.6704 - val_loss: 0.5971 - val_acc: 0.6970\n",
      "Epoch 12/150\n",
      "537/537 [==============================] - 0s 516us/step - loss: 0.6060 - acc: 0.6797 - val_loss: 0.5953 - val_acc: 0.6970\n",
      "Epoch 13/150\n",
      "537/537 [==============================] - 0s 821us/step - loss: 0.5905 - acc: 0.6909 - val_loss: 0.5956 - val_acc: 0.6840\n",
      "Epoch 14/150\n",
      "537/537 [==============================] - 0s 512us/step - loss: 0.5961 - acc: 0.6946 - val_loss: 0.5895 - val_acc: 0.7186\n",
      "Epoch 15/150\n",
      "537/537 [==============================] - 0s 522us/step - loss: 0.5981 - acc: 0.6778 - val_loss: 0.5865 - val_acc: 0.7013\n",
      "Epoch 16/150\n",
      "537/537 [==============================] - 0s 616us/step - loss: 0.5871 - acc: 0.7039 - val_loss: 0.5859 - val_acc: 0.7013\n",
      "Epoch 17/150\n",
      "537/537 [==============================] - 0s 758us/step - loss: 0.5944 - acc: 0.6872 - val_loss: 0.5891 - val_acc: 0.6840\n",
      "Epoch 18/150\n",
      "537/537 [==============================] - 0s 817us/step - loss: 0.5972 - acc: 0.6965 - val_loss: 0.5938 - val_acc: 0.6623\n",
      "Epoch 19/150\n",
      "537/537 [==============================] - 0s 425us/step - loss: 0.5926 - acc: 0.7095 - val_loss: 0.5808 - val_acc: 0.7186\n",
      "Epoch 20/150\n",
      "537/537 [==============================] - 0s 545us/step - loss: 0.5878 - acc: 0.7169 - val_loss: 0.5780 - val_acc: 0.7056\n",
      "Epoch 21/150\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.5727 - acc: 0.719 - 0s 369us/step - loss: 0.5729 - acc: 0.7207 - val_loss: 0.5786 - val_acc: 0.7143\n",
      "Epoch 22/150\n",
      "537/537 [==============================] - 0s 371us/step - loss: 0.5846 - acc: 0.7076 - val_loss: 0.5755 - val_acc: 0.7013\n",
      "Epoch 23/150\n",
      "537/537 [==============================] - 0s 401us/step - loss: 0.5857 - acc: 0.7132 - val_loss: 0.5786 - val_acc: 0.7186\n",
      "Epoch 24/150\n",
      "537/537 [==============================] - 0s 398us/step - loss: 0.5776 - acc: 0.7095 - val_loss: 0.5849 - val_acc: 0.6926\n",
      "Epoch 25/150\n",
      "537/537 [==============================] - 0s 362us/step - loss: 0.5790 - acc: 0.7002 - val_loss: 0.5741 - val_acc: 0.7186\n",
      "Epoch 26/150\n",
      "537/537 [==============================] - 0s 367us/step - loss: 0.5763 - acc: 0.7132 - val_loss: 0.5720 - val_acc: 0.7273\n",
      "Epoch 27/150\n",
      "537/537 [==============================] - 0s 372us/step - loss: 0.5727 - acc: 0.7058 - val_loss: 0.5768 - val_acc: 0.6970\n",
      "Epoch 28/150\n",
      "537/537 [==============================] - 0s 362us/step - loss: 0.5701 - acc: 0.7169 - val_loss: 0.5771 - val_acc: 0.7143\n",
      "Epoch 29/150\n",
      "537/537 [==============================] - 0s 350us/step - loss: 0.5710 - acc: 0.7225 - val_loss: 0.5679 - val_acc: 0.7143\n",
      "Epoch 30/150\n",
      "537/537 [==============================] - 0s 369us/step - loss: 0.5647 - acc: 0.7151 - val_loss: 0.5707 - val_acc: 0.6970\n",
      "Epoch 31/150\n",
      "537/537 [==============================] - 0s 546us/step - loss: 0.5537 - acc: 0.7356 - val_loss: 0.5696 - val_acc: 0.7056\n",
      "Epoch 32/150\n",
      "537/537 [==============================] - 0s 470us/step - loss: 0.5528 - acc: 0.7505 - val_loss: 0.5807 - val_acc: 0.7143\n",
      "Epoch 33/150\n",
      "537/537 [==============================] - 0s 517us/step - loss: 0.5484 - acc: 0.7561 - val_loss: 0.5603 - val_acc: 0.7100\n",
      "Epoch 34/150\n",
      "537/537 [==============================] - 0s 471us/step - loss: 0.5618 - acc: 0.7207 - val_loss: 0.5520 - val_acc: 0.7273\n",
      "Epoch 35/150\n",
      "537/537 [==============================] - 0s 384us/step - loss: 0.5539 - acc: 0.7393 - val_loss: 0.5706 - val_acc: 0.7229\n",
      "Epoch 36/150\n",
      "537/537 [==============================] - 0s 543us/step - loss: 0.5408 - acc: 0.7393 - val_loss: 0.5674 - val_acc: 0.7316\n",
      "Epoch 37/150\n",
      "537/537 [==============================] - 0s 423us/step - loss: 0.5589 - acc: 0.6983 - val_loss: 0.5502 - val_acc: 0.7229\n",
      "Epoch 38/150\n",
      "537/537 [==============================] - 0s 398us/step - loss: 0.5482 - acc: 0.7263 - val_loss: 0.5526 - val_acc: 0.7229\n",
      "Epoch 39/150\n",
      "537/537 [==============================] - 0s 415us/step - loss: 0.5472 - acc: 0.7169 - val_loss: 0.5606 - val_acc: 0.7446\n",
      "Epoch 40/150\n",
      "537/537 [==============================] - 0s 405us/step - loss: 0.5441 - acc: 0.7542 - val_loss: 0.5510 - val_acc: 0.7143\n",
      "Epoch 41/150\n",
      "537/537 [==============================] - 0s 388us/step - loss: 0.5323 - acc: 0.7430 - val_loss: 0.5458 - val_acc: 0.7229\n",
      "Epoch 42/150\n",
      "537/537 [==============================] - 0s 538us/step - loss: 0.5402 - acc: 0.7467 - val_loss: 0.5514 - val_acc: 0.7143\n",
      "Epoch 43/150\n",
      "537/537 [==============================] - 0s 510us/step - loss: 0.5441 - acc: 0.7281 - val_loss: 0.5426 - val_acc: 0.7186\n",
      "Epoch 44/150\n",
      "537/537 [==============================] - 0s 420us/step - loss: 0.5472 - acc: 0.7225 - val_loss: 0.5711 - val_acc: 0.7100\n",
      "Epoch 45/150\n",
      "537/537 [==============================] - 0s 514us/step - loss: 0.5302 - acc: 0.7598 - val_loss: 0.5422 - val_acc: 0.7229\n",
      "Epoch 46/150\n",
      "537/537 [==============================] - 0s 564us/step - loss: 0.5396 - acc: 0.7374 - val_loss: 0.5468 - val_acc: 0.7229\n",
      "Epoch 47/150\n",
      "537/537 [==============================] - 0s 608us/step - loss: 0.5310 - acc: 0.7393 - val_loss: 0.5428 - val_acc: 0.7143\n",
      "Epoch 48/150\n",
      "537/537 [==============================] - 0s 634us/step - loss: 0.5349 - acc: 0.7449 - val_loss: 0.5515 - val_acc: 0.7186\n",
      "Epoch 49/150\n",
      "537/537 [==============================] - 0s 712us/step - loss: 0.5385 - acc: 0.7412 - val_loss: 0.5649 - val_acc: 0.7273\n",
      "Epoch 50/150\n",
      "537/537 [==============================] - 0s 588us/step - loss: 0.5397 - acc: 0.7523 - val_loss: 0.5584 - val_acc: 0.7186\n",
      "Epoch 51/150\n",
      "537/537 [==============================] - 0s 714us/step - loss: 0.5442 - acc: 0.7225 - val_loss: 0.5359 - val_acc: 0.7316\n",
      "Epoch 52/150\n",
      "537/537 [==============================] - 0s 531us/step - loss: 0.5168 - acc: 0.7505 - val_loss: 0.5538 - val_acc: 0.7359\n",
      "Epoch 53/150\n",
      "537/537 [==============================] - 0s 534us/step - loss: 0.5206 - acc: 0.7505 - val_loss: 0.5456 - val_acc: 0.7273\n",
      "Epoch 54/150\n",
      "537/537 [==============================] - 0s 693us/step - loss: 0.5242 - acc: 0.7374 - val_loss: 0.5775 - val_acc: 0.7143\n",
      "Epoch 55/150\n",
      "537/537 [==============================] - 0s 669us/step - loss: 0.5217 - acc: 0.7449 - val_loss: 0.5490 - val_acc: 0.7229\n",
      "Epoch 56/150\n",
      "537/537 [==============================] - 0s 687us/step - loss: 0.5172 - acc: 0.7542 - val_loss: 0.5356 - val_acc: 0.7446\n",
      "Epoch 57/150\n",
      "537/537 [==============================] - 0s 652us/step - loss: 0.5245 - acc: 0.7561 - val_loss: 0.5367 - val_acc: 0.7316\n",
      "Epoch 58/150\n",
      "537/537 [==============================] - 0s 706us/step - loss: 0.5234 - acc: 0.7486 - val_loss: 0.5440 - val_acc: 0.7273\n",
      "Epoch 59/150\n",
      "537/537 [==============================] - 0s 724us/step - loss: 0.5290 - acc: 0.7449 - val_loss: 0.5514 - val_acc: 0.7359\n",
      "Epoch 60/150\n",
      "537/537 [==============================] - 0s 621us/step - loss: 0.5094 - acc: 0.7523 - val_loss: 0.5364 - val_acc: 0.7229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/150\n",
      "537/537 [==============================] - 0s 472us/step - loss: 0.5098 - acc: 0.7691 - val_loss: 0.5536 - val_acc: 0.7273\n",
      "Epoch 62/150\n",
      "537/537 [==============================] - 0s 391us/step - loss: 0.5418 - acc: 0.7337 - val_loss: 0.5898 - val_acc: 0.7013\n",
      "Epoch 63/150\n",
      "537/537 [==============================] - 0s 400us/step - loss: 0.5115 - acc: 0.7356 - val_loss: 0.5294 - val_acc: 0.7273\n",
      "Epoch 64/150\n",
      "537/537 [==============================] - 0s 388us/step - loss: 0.5159 - acc: 0.7337 - val_loss: 0.5343 - val_acc: 0.7316\n",
      "Epoch 65/150\n",
      "537/537 [==============================] - 0s 398us/step - loss: 0.5022 - acc: 0.7691 - val_loss: 0.5317 - val_acc: 0.7186\n",
      "Epoch 66/150\n",
      "537/537 [==============================] - 0s 674us/step - loss: 0.5035 - acc: 0.7747 - val_loss: 0.5495 - val_acc: 0.7186\n",
      "Epoch 67/150\n",
      "537/537 [==============================] - 0s 481us/step - loss: 0.5078 - acc: 0.7467 - val_loss: 0.5311 - val_acc: 0.7403\n",
      "Epoch 68/150\n",
      "537/537 [==============================] - 0s 391us/step - loss: 0.5152 - acc: 0.7449 - val_loss: 0.5339 - val_acc: 0.7316\n",
      "Epoch 69/150\n",
      "537/537 [==============================] - 0s 418us/step - loss: 0.5165 - acc: 0.7542 - val_loss: 0.5302 - val_acc: 0.7359\n",
      "Epoch 70/150\n",
      "537/537 [==============================] - 0s 510us/step - loss: 0.5020 - acc: 0.7486 - val_loss: 0.5248 - val_acc: 0.7359\n",
      "Epoch 71/150\n",
      "537/537 [==============================] - 0s 513us/step - loss: 0.4992 - acc: 0.7654 - val_loss: 0.5279 - val_acc: 0.7403\n",
      "Epoch 72/150\n",
      "537/537 [==============================] - 0s 530us/step - loss: 0.5011 - acc: 0.7467 - val_loss: 0.5316 - val_acc: 0.7229\n",
      "Epoch 73/150\n",
      "537/537 [==============================] - 0s 499us/step - loss: 0.5056 - acc: 0.7654 - val_loss: 0.5378 - val_acc: 0.7316\n",
      "Epoch 74/150\n",
      "537/537 [==============================] - 0s 694us/step - loss: 0.5128 - acc: 0.7374 - val_loss: 0.5250 - val_acc: 0.7403\n",
      "Epoch 75/150\n",
      "537/537 [==============================] - 0s 701us/step - loss: 0.5001 - acc: 0.7691 - val_loss: 0.5366 - val_acc: 0.7273\n",
      "Epoch 76/150\n",
      "537/537 [==============================] - 0s 516us/step - loss: 0.4908 - acc: 0.7728 - val_loss: 0.5289 - val_acc: 0.7359\n",
      "Epoch 77/150\n",
      "537/537 [==============================] - 0s 499us/step - loss: 0.5002 - acc: 0.7505 - val_loss: 0.5271 - val_acc: 0.7229\n",
      "Epoch 78/150\n",
      "537/537 [==============================] - 0s 491us/step - loss: 0.4876 - acc: 0.7821 - val_loss: 0.5334 - val_acc: 0.7186\n",
      "Epoch 79/150\n",
      "537/537 [==============================] - 0s 522us/step - loss: 0.5031 - acc: 0.7561 - val_loss: 0.5314 - val_acc: 0.7229\n",
      "Epoch 80/150\n",
      "537/537 [==============================] - 0s 524us/step - loss: 0.5031 - acc: 0.7374 - val_loss: 0.5331 - val_acc: 0.7273\n",
      "Epoch 81/150\n",
      "537/537 [==============================] - 0s 524us/step - loss: 0.4989 - acc: 0.7542 - val_loss: 0.5336 - val_acc: 0.7273\n",
      "Epoch 82/150\n",
      "537/537 [==============================] - 0s 711us/step - loss: 0.4951 - acc: 0.7616 - val_loss: 0.5279 - val_acc: 0.7143\n",
      "Epoch 83/150\n",
      "537/537 [==============================] - 0s 645us/step - loss: 0.4878 - acc: 0.7616 - val_loss: 0.5224 - val_acc: 0.7403\n",
      "Epoch 84/150\n",
      "537/537 [==============================] - 0s 698us/step - loss: 0.4984 - acc: 0.7654 - val_loss: 0.5307 - val_acc: 0.7273\n",
      "Epoch 85/150\n",
      "537/537 [==============================] - 0s 659us/step - loss: 0.4914 - acc: 0.7523 - val_loss: 0.5350 - val_acc: 0.7576\n",
      "Epoch 86/150\n",
      "537/537 [==============================] - 0s 718us/step - loss: 0.4952 - acc: 0.7561 - val_loss: 0.5279 - val_acc: 0.7619\n",
      "Epoch 87/150\n",
      "537/537 [==============================] - 0s 481us/step - loss: 0.4790 - acc: 0.7635 - val_loss: 0.5416 - val_acc: 0.7316\n",
      "Epoch 88/150\n",
      "537/537 [==============================] - 0s 528us/step - loss: 0.5002 - acc: 0.7579 - val_loss: 0.5301 - val_acc: 0.7359\n",
      "Epoch 89/150\n",
      "537/537 [==============================] - 0s 539us/step - loss: 0.4912 - acc: 0.7542 - val_loss: 0.5294 - val_acc: 0.7273\n",
      "Epoch 90/150\n",
      "537/537 [==============================] - 0s 535us/step - loss: 0.4830 - acc: 0.7765 - val_loss: 0.5204 - val_acc: 0.7662\n",
      "Epoch 91/150\n",
      "537/537 [==============================] - 0s 591us/step - loss: 0.4758 - acc: 0.7635 - val_loss: 0.5201 - val_acc: 0.7489\n",
      "Epoch 92/150\n",
      "537/537 [==============================] - 0s 572us/step - loss: 0.4738 - acc: 0.7616 - val_loss: 0.5239 - val_acc: 0.7403\n",
      "Epoch 93/150\n",
      "537/537 [==============================] - 0s 700us/step - loss: 0.4798 - acc: 0.7542 - val_loss: 0.5327 - val_acc: 0.7359\n",
      "Epoch 94/150\n",
      "537/537 [==============================] - 0s 521us/step - loss: 0.4806 - acc: 0.7728 - val_loss: 0.5215 - val_acc: 0.7532\n",
      "Epoch 95/150\n",
      "537/537 [==============================] - 0s 576us/step - loss: 0.4756 - acc: 0.7747 - val_loss: 0.5198 - val_acc: 0.7446\n",
      "Epoch 96/150\n",
      "537/537 [==============================] - 0s 540us/step - loss: 0.4728 - acc: 0.7821 - val_loss: 0.5218 - val_acc: 0.7186\n",
      "Epoch 97/150\n",
      "537/537 [==============================] - 0s 512us/step - loss: 0.4789 - acc: 0.7765 - val_loss: 0.5208 - val_acc: 0.7316\n",
      "Epoch 98/150\n",
      "537/537 [==============================] - 0s 711us/step - loss: 0.4781 - acc: 0.7784 - val_loss: 0.5277 - val_acc: 0.7100\n",
      "Epoch 99/150\n",
      "537/537 [==============================] - 0s 539us/step - loss: 0.4797 - acc: 0.7654 - val_loss: 0.5090 - val_acc: 0.7316\n",
      "Epoch 100/150\n",
      "537/537 [==============================] - 0s 508us/step - loss: 0.4697 - acc: 0.7747 - val_loss: 0.5129 - val_acc: 0.7316\n",
      "Epoch 101/150\n",
      "537/537 [==============================] - 0s 551us/step - loss: 0.4727 - acc: 0.7579 - val_loss: 0.5263 - val_acc: 0.7446\n",
      "Epoch 102/150\n",
      "537/537 [==============================] - 0s 580us/step - loss: 0.4734 - acc: 0.7635 - val_loss: 0.5664 - val_acc: 0.7273\n",
      "Epoch 103/150\n",
      "537/537 [==============================] - 0s 524us/step - loss: 0.4748 - acc: 0.7747 - val_loss: 0.5157 - val_acc: 0.7619\n",
      "Epoch 104/150\n",
      "537/537 [==============================] - 0s 652us/step - loss: 0.4808 - acc: 0.7765 - val_loss: 0.5190 - val_acc: 0.7273\n",
      "Epoch 105/150\n",
      "537/537 [==============================] - 0s 525us/step - loss: 0.4700 - acc: 0.7728 - val_loss: 0.5385 - val_acc: 0.7186\n",
      "Epoch 106/150\n",
      "537/537 [==============================] - 0s 595us/step - loss: 0.4793 - acc: 0.7561 - val_loss: 0.5136 - val_acc: 0.7273\n",
      "Epoch 107/150\n",
      "537/537 [==============================] - 0s 502us/step - loss: 0.4563 - acc: 0.7803 - val_loss: 0.5342 - val_acc: 0.7143\n",
      "Epoch 108/150\n",
      "537/537 [==============================] - 0s 489us/step - loss: 0.4646 - acc: 0.7672 - val_loss: 0.5615 - val_acc: 0.7316\n",
      "Epoch 109/150\n",
      "537/537 [==============================] - 0s 600us/step - loss: 0.4899 - acc: 0.7542 - val_loss: 0.5021 - val_acc: 0.7619\n",
      "Epoch 110/150\n",
      "537/537 [==============================] - 0s 639us/step - loss: 0.4698 - acc: 0.7765 - val_loss: 0.5099 - val_acc: 0.7662\n",
      "Epoch 111/150\n",
      "537/537 [==============================] - 0s 569us/step - loss: 0.4719 - acc: 0.7635 - val_loss: 0.5141 - val_acc: 0.7576\n",
      "Epoch 112/150\n",
      "537/537 [==============================] - 0s 531us/step - loss: 0.4578 - acc: 0.7728 - val_loss: 0.5176 - val_acc: 0.7489\n",
      "Epoch 113/150\n",
      "537/537 [==============================] - 0s 561us/step - loss: 0.4845 - acc: 0.7784 - val_loss: 0.5087 - val_acc: 0.7403\n",
      "Epoch 114/150\n",
      "537/537 [==============================] - 0s 496us/step - loss: 0.4728 - acc: 0.7616 - val_loss: 0.5022 - val_acc: 0.7619\n",
      "Epoch 115/150\n",
      "537/537 [==============================] - 0s 612us/step - loss: 0.4471 - acc: 0.7896 - val_loss: 0.5179 - val_acc: 0.7229\n",
      "Epoch 116/150\n",
      "537/537 [==============================] - 0s 525us/step - loss: 0.4450 - acc: 0.7784 - val_loss: 0.5155 - val_acc: 0.7662\n",
      "Epoch 117/150\n",
      "537/537 [==============================] - 0s 582us/step - loss: 0.4679 - acc: 0.7709 - val_loss: 0.5274 - val_acc: 0.7229\n",
      "Epoch 118/150\n",
      "537/537 [==============================] - 0s 517us/step - loss: 0.4699 - acc: 0.7672 - val_loss: 0.5122 - val_acc: 0.7749\n",
      "Epoch 119/150\n",
      "537/537 [==============================] - 0s 576us/step - loss: 0.4628 - acc: 0.7728 - val_loss: 0.5605 - val_acc: 0.7056\n",
      "Epoch 120/150\n",
      "537/537 [==============================] - 0s 630us/step - loss: 0.4430 - acc: 0.7840 - val_loss: 0.5144 - val_acc: 0.7359\n",
      "Epoch 121/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 530us/step - loss: 0.4705 - acc: 0.7635 - val_loss: 0.4995 - val_acc: 0.7489\n",
      "Epoch 122/150\n",
      "537/537 [==============================] - 0s 435us/step - loss: 0.4490 - acc: 0.7952 - val_loss: 0.5206 - val_acc: 0.7489\n",
      "Epoch 123/150\n",
      "537/537 [==============================] - 0s 443us/step - loss: 0.4624 - acc: 0.7821 - val_loss: 0.5136 - val_acc: 0.7792\n",
      "Epoch 124/150\n",
      "537/537 [==============================] - 0s 497us/step - loss: 0.4696 - acc: 0.7672 - val_loss: 0.5050 - val_acc: 0.7359\n",
      "Epoch 125/150\n",
      "537/537 [==============================] - 0s 487us/step - loss: 0.4411 - acc: 0.7877 - val_loss: 0.5081 - val_acc: 0.7749\n",
      "Epoch 126/150\n",
      "537/537 [==============================] - 0s 494us/step - loss: 0.4553 - acc: 0.7654 - val_loss: 0.5304 - val_acc: 0.7576\n",
      "Epoch 127/150\n",
      "537/537 [==============================] - 0s 512us/step - loss: 0.4984 - acc: 0.7672 - val_loss: 0.5159 - val_acc: 0.7403\n",
      "Epoch 128/150\n",
      "537/537 [==============================] - 0s 474us/step - loss: 0.4692 - acc: 0.7709 - val_loss: 0.5120 - val_acc: 0.7316\n",
      "Epoch 129/150\n",
      "537/537 [==============================] - 0s 776us/step - loss: 0.4418 - acc: 0.7896 - val_loss: 0.5081 - val_acc: 0.7229\n",
      "Epoch 130/150\n",
      "537/537 [==============================] - 0s 574us/step - loss: 0.4721 - acc: 0.7728 - val_loss: 0.4975 - val_acc: 0.7359\n",
      "Epoch 131/150\n",
      "537/537 [==============================] - 0s 486us/step - loss: 0.4577 - acc: 0.7784 - val_loss: 0.4958 - val_acc: 0.7662\n",
      "Epoch 132/150\n",
      "537/537 [==============================] - 0s 581us/step - loss: 0.4470 - acc: 0.7803 - val_loss: 0.5154 - val_acc: 0.7316\n",
      "Epoch 133/150\n",
      "537/537 [==============================] - 0s 535us/step - loss: 0.4489 - acc: 0.7747 - val_loss: 0.5321 - val_acc: 0.7446\n",
      "Epoch 134/150\n",
      "537/537 [==============================] - 0s 523us/step - loss: 0.4426 - acc: 0.7952 - val_loss: 0.4999 - val_acc: 0.7619\n",
      "Epoch 135/150\n",
      "537/537 [==============================] - 0s 520us/step - loss: 0.4343 - acc: 0.7803 - val_loss: 0.5259 - val_acc: 0.7273\n",
      "Epoch 136/150\n",
      "537/537 [==============================] - 0s 505us/step - loss: 0.4563 - acc: 0.7803 - val_loss: 0.5243 - val_acc: 0.7273\n",
      "Epoch 137/150\n",
      "537/537 [==============================] - 0s 510us/step - loss: 0.4258 - acc: 0.7970 - val_loss: 0.5098 - val_acc: 0.7792\n",
      "Epoch 138/150\n",
      "537/537 [==============================] - 0s 534us/step - loss: 0.4592 - acc: 0.7691 - val_loss: 0.5143 - val_acc: 0.7359\n",
      "Epoch 139/150\n",
      "537/537 [==============================] - 0s 646us/step - loss: 0.4507 - acc: 0.7896 - val_loss: 0.5203 - val_acc: 0.7446\n",
      "Epoch 140/150\n",
      "537/537 [==============================] - 0s 499us/step - loss: 0.4394 - acc: 0.7709 - val_loss: 0.4988 - val_acc: 0.7489\n",
      "Epoch 141/150\n",
      "537/537 [==============================] - 0s 526us/step - loss: 0.4362 - acc: 0.7896 - val_loss: 0.5111 - val_acc: 0.7706\n",
      "Epoch 142/150\n",
      "537/537 [==============================] - 0s 529us/step - loss: 0.4460 - acc: 0.7821 - val_loss: 0.4901 - val_acc: 0.7619\n",
      "Epoch 143/150\n",
      "537/537 [==============================] - 0s 516us/step - loss: 0.4311 - acc: 0.8007 - val_loss: 0.5177 - val_acc: 0.7662\n",
      "Epoch 144/150\n",
      "537/537 [==============================] - 0s 505us/step - loss: 0.4366 - acc: 0.8045 - val_loss: 0.4995 - val_acc: 0.7662\n",
      "Epoch 145/150\n",
      "537/537 [==============================] - 0s 501us/step - loss: 0.4487 - acc: 0.7896 - val_loss: 0.5127 - val_acc: 0.7835\n",
      "Epoch 146/150\n",
      "537/537 [==============================] - 0s 565us/step - loss: 0.4492 - acc: 0.7635 - val_loss: 0.4946 - val_acc: 0.7835\n",
      "Epoch 147/150\n",
      "537/537 [==============================] - 0s 487us/step - loss: 0.4341 - acc: 0.7784 - val_loss: 0.5511 - val_acc: 0.7403\n",
      "Epoch 148/150\n",
      "537/537 [==============================] - 0s 491us/step - loss: 0.4405 - acc: 0.7747 - val_loss: 0.5106 - val_acc: 0.7489\n",
      "Epoch 149/150\n",
      "537/537 [==============================] - 0s 548us/step - loss: 0.4256 - acc: 0.8119 - val_loss: 0.5129 - val_acc: 0.7532\n",
      "Epoch 150/150\n",
      "537/537 [==============================] - 0s 518us/step - loss: 0.4562 - acc: 0.7765 - val_loss: 0.5016 - val_acc: 0.7403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8229a8a0b8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, validation_data=(X_test,Y_test), nb_epoch=150 , batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 0s 66us/step\n",
      "Test loss: 0.5015679445617642\n",
      "Test accuracy: 0.7402597403887546\n"
     ]
    }
   ],
   "source": [
    "# Desempenho do modelo \n",
    "scores = model.evaluate(X_test, Y_test, verbose = 1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
