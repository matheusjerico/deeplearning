{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# blobfromImage - Preprocessamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n01440764 tench, Tinca tinca', 'n01443537 goldfish, Carassius auratus', 'n01484850 great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias', 'n01491361 tiger shark, Galeocerdo cuvieri', 'n01494475 hammerhead, hammerhead shark']\n",
      "['tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead']\n"
     ]
    }
   ],
   "source": [
    "# Carrega as classes\n",
    "synset_words_path = '/home/matheusjerico/Documentos/DSA/05. MachineLearning/Cap-12-IntroduçãoDeepLearning/blobFromImages/synset_words.txt'\n",
    "\n",
    "# Carrega as linhas\n",
    "rows = open(synset_words_path).read().strip().split('\\n')\n",
    "print(rows[:5])\n",
    "classes = [r[r.find(\" \") + 1:].split(\",\")[0] for r in rows]\n",
    "print(classes[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colocando em variável o caminho dos arquivos\n",
    "prototxt_path  = '/home/matheusjerico/Documentos/DSA/05. MachineLearning/Cap-12-IntroduçãoDeepLearning/blobFromImages/bvlc_googlenet.prototxt'\n",
    "caffemodel_path = '/home/matheusjerico/Documentos/DSA/05. MachineLearning/Cap-12-IntroduçãoDeepLearning/blobFromImages/bvlc_googlenet.caffemodel'\n",
    "image_path = '/home/matheusjerico/Documentos/DSA/05. MachineLearning/Cap-12-IntroduçãoDeepLearning/blobFromImages/images/'\n",
    "\n",
    "# Carrega parametros e modelo\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path,caffemodel_path)\n",
    "\n",
    "# Carrega lista de imagens\n",
    "imagePaths = sorted(list(paths.list_images(image_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first blob: (1, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "# Carregando imagem\n",
    "image = cv2.imread(imagePaths[0])\n",
    "\n",
    "# Redimencionando imagem\n",
    "image_resized = cv2.resize(image, (224,224))\n",
    "\n",
    "# Construindo o blob\n",
    "blob = cv2.dnn.blobFromImage(image_resized, 1, (224, 224), (104, 117, 123))\n",
    "print(\"first blob: {}\".format(blob.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defina a entrada para a rede de aprendizagem profunda pré-treinada\n",
    "# e obtenha as probabilidades previstas de saída para cada uma das 1.000 classes ImageNet\n",
    "net.setInput(blob)\n",
    "preds = net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ordene a ordem das probabilidades (em ordem decrescente),\n",
    "# pegue o índice do rótulo predito superior e desenhe-o na imagem de entrada\n",
    "idx = np.argsort(preds[0])[::-1][0]\n",
    "text = \"Label: {}, {:.2f}%\".format(classes[idx], preds[0][idx]*100)\n",
    "cv2.putText(image, text, (5, 25), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "           0.7, (0, 0, 225), 2)\n",
    "\n",
    "# mostrar imagem de entrada\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# blobfromImages - Preprocessamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second blob: (5, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "# Carregando muliplas imagens\n",
    "images = []\n",
    "\n",
    "for i in imagePaths:\n",
    "    image = cv2.imread(i)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    images.append(image)\n",
    "\n",
    "blob = cv2.dnn.blobFromImages(images, 1, (224, 224), (104, 117, 123))\n",
    "print(\"Second blob: {}\".format(blob.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defina a entrada para a rede de aprendizagem profunda pré-treinada\n",
    "# e obtenha as probabilidades previstas de saída para cada uma das 1.000 classes ImageNet\n",
    "net.setInput(blob)\n",
    "preds = net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, p) in enumerate(imagePaths):\n",
    "    image = cv2.imread(p)\n",
    "    \n",
    "    idx = np.argsort(preds[i])[::-1][0]\n",
    "    text = \"Label: {}, {:.2f}%\".format(classes[idx], preds[i][idx]*100)\n",
    "    cv2.putText(image, text, (5, 25), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "           0.7, (0, 0, 225), 2)\n",
    "    \n",
    "    # mostrar imagem de entrada\n",
    "    cv2.imshow(\"Image\", image)\n",
    "    cv2.waitKey()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
